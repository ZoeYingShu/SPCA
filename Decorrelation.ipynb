{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import inspect\n",
    "\n",
    "# SPCA libraries\n",
    "from SPCA import helpers, astro_models, make_plots, make_plots_custom, detec_models, bliss, freeze\n",
    "from SPCA import Decorrelation_helper as dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter in parameters that will define how the rest of the code will run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet = 'KELT-16b'\n",
    "channel = 'ch2'\n",
    "mode = 'Poly2_v1'\n",
    "rootpath = '/home/taylor/Documents/Research/spitzer/MEGA/'\n",
    "\n",
    "# parameters you do not wish to fit\n",
    "dparams_input = []\n",
    "\n",
    "# parameters you want to place a gaussian prior on\n",
    "gparams = ['t0', 'per', 'a', 'inc']\n",
    "\n",
    "# parameters you want to place a uniform prior on\n",
    "uparams = ['rp', 'fp', 'q1', 'q2', 'inc', 'ecosw', 'esinw', 'sigF', 'gpLx', 'gpLy']\n",
    "uparams_limits = [[0,1], [0,1], [0,1], [0,1], [70,90], [-1,1], [-1,1], [0,1], [0,-3],[0,-3]]\n",
    "uparams.extend(['p'+str(i)+'_1' for i in range(1,26)]) # First order PLD terms\n",
    "uparams.extend(['p'+str(i)+'_2' for i in range(1,26)]) # Second order PLD terms\n",
    "uparams_limits.extend([[-3,3] for i in range(1,26)])\n",
    "uparams_limits.extend([[-500,500] for i in range(1,26)])\n",
    "\n",
    "oldPhotometry = False                    # Whether photometry was computed before May 1, 2020 when flux conversion was patched\n",
    "ncpu = 4                                 # The number of cpu threads to be used when running MCMC\n",
    "runMCMC = True                           # whether to run MCMC or just load-in past results\n",
    "nIterScipy = 10                          # Number of iterative scipy runs used to locate best-fit before starting MCMCs\n",
    "nBurnInSteps2 = 7.5e5                    # number of steps to use for the second mcmc burn-in\n",
    "nProductionSteps = 1.5e5                 # number of steps to use with mcmc production run\n",
    "usebestfit = True                        # used best-fit instead of median of chain\n",
    "blissNBin = 8                            # number of knots to allow in each direction\n",
    "secondOrderOffset = False                # should you use the second order sinusoid terms when calculating offset\n",
    "bestfitNbin = 50                         # the number of binned values to overplot on the bestfit 4-panel figure (use None if you don't want these overplotted)\n",
    "nFrames  = 64                            # number of frames per binned data point\n",
    "initializeWithOld = False                # initial with previous mcmc results using the same method\n",
    "pldIgnoreFrames = True                   # Whether or not to use the PLD photometry that ignored bad frames\n",
    "pldAddStack = False                      # Whether or not to use the PLD photometry that used background correction stacks\n",
    "debug = False                            # True if user wants details about the lambda functions created\n",
    "\n",
    "#non-unity if you have dilution by a nearby companion\n",
    "compFactor = 1.\n",
    "\n",
    "# non-zero if you want to remove some initial data points\n",
    "cut_tmp = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything below can be run without interfering with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rootpath[-1]!='/':\n",
    "    rootpath += '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out where data is located\n",
    "if 'pldaper' in mode.lower():\n",
    "    # Get separately aperture data for when running PLDAper, and decide if ignoreFrame from aperture photometry\n",
    "    foldername_aper = dh.findPhotometry(rootpath, planet, channel, 'Poly2_v1')[0]\n",
    "    if len(ignoreFrames)==0:\n",
    "        pldIgnoreFrames = False\n",
    "    else:\n",
    "        pldIgnoreFrames = True\n",
    "    foldername_psf = ''\n",
    "else:\n",
    "    foldername_aper = ''\n",
    "\n",
    "if 'psfx' in mode.lower():\n",
    "    foldername_psf = dh.findPhotometry(rootpath, planet, channel, 'PSFX')[0]\n",
    "else:\n",
    "    foldername_psf = ''\n",
    "\n",
    "(foldername, filename, filename_full, savepath,\n",
    "path_params, AOR_snip, aors, breaks, ignoreFrames) = dh.findPhotometry(rootpath, planet, channel,\n",
    "                                                                       mode, pldIgnoreFrames, pldAddStack)\n",
    "\n",
    "with open(rootpath+planet+'/analysis/'+channel+'/cutFirstAOR.txt', 'r') as file:\n",
    "    cutFirstAOR = file.readline().strip()=='True'\n",
    "\n",
    "# For datasets where the first AOR is peak-up data\n",
    "if cutFirstAOR:\n",
    "    rawfiles = np.sort(os.listdir(rootpath+planet+'/data/'+channel+'/'+aors[0]+'/'+channel+'/bcd/'))\n",
    "    rawfiles  = [rawfile for rawfile in rawfiles if '_bcd.fits' in rawfile]\n",
    "    cut = cut_tmp+len(rawfiles)\n",
    "else:\n",
    "    cut = cut_tmp\n",
    "\n",
    "# loading full data set for BIC calculation afterwards\n",
    "if 'pld' in mode.lower():\n",
    "    # get data from unbinned photometry for chi2 on unbinned data calculation later\n",
    "    Pnorm_full, flux_full, time_full = helpers.get_full_data(foldername, filename_full, mode,\n",
    "                                                             foldername_aper=foldername_aper,\n",
    "                                                             cut=cut, nFrames=nFrames, ignore=ignoreFrames)\n",
    "    # Get Data we'll analyze\n",
    "    Pnorm_0, flux0, time0 = helpers.get_data(foldername, filename, mode,\n",
    "                                             foldername_aper=foldername_aper)\n",
    "    Pnorm, flux, time = helpers.get_data(foldername, filename, mode,\n",
    "                                         foldername_aper=foldername_aper, cut=cut)\n",
    "    \n",
    "    pca = PCA(n_components=int(Pnorm_full.shape[0]-1))\n",
    "    pca.fit(Pnorm_full.T)\n",
    "    Pnorm_full = pca.transform(Pnorm_full.T).T\n",
    "    Pnorm_full = np.append(np.ones_like(Pnorm_full[:1]), Pnorm_full, axis=0)\n",
    "    \n",
    "    pca = PCA(n_components=int(Pnorm.shape[0]-1))\n",
    "    pca.fit(Pnorm.T)\n",
    "    Pnorm = pca.transform(Pnorm.T).T\n",
    "    Pnorm = np.append(np.ones_like(Pnorm[:1]), Pnorm, axis=0)\n",
    "    \n",
    "    if not oldPhotometry:\n",
    "        if 'pldaper' in mode.lower():\n",
    "            path_temp = foldername_aper+filename\n",
    "        else:\n",
    "            path_temp = foldername+filename\n",
    "        sigF_photon_ppm = dh.get_photon_limit(path_temp, mode, nFrames, ignoreFrames)\n",
    "    \n",
    "    # FIX: Add an initial PLD plot\n",
    "else:\n",
    "    # get data from photometry\n",
    "    (flux_full, time_full, xdata_full, ydata_full,\n",
    "     psfxw_full, psfyw_full) = helpers.get_full_data(foldername, filename_full, mode,\n",
    "                                                     foldername_psf=foldername_psf,\n",
    "                                                     cut=cut, nFrames=nFrames, ignore=ignoreFrames)\n",
    "    # Get Data we'll analyze\n",
    "    (flux0, time0, xdata0, ydata0, psfxw0, psfyw0) = helpers.get_data(foldername, filename, mode,\n",
    "                                                                      foldername_psf=foldername_psf)\n",
    "    (flux, time, xdata, ydata, psfxw, psfyw) = helpers.get_data(foldername, filename, mode,\n",
    "                                                                foldername_psf=foldername_psf, cut=cut)\n",
    "    \n",
    "    if not oldPhotometry:\n",
    "        sigF_photon_ppm = dh.get_photon_limit(foldername+filename, mode, nFrames, ignoreFrames)\n",
    "    \n",
    "    ## FIX: peritime doesn't get made\n",
    "    if True:#'ecosw' in dparams_input and 'esinw' in dparams_input:\n",
    "        # make photometry plots\n",
    "        make_plots.plot_photometry(time0, flux0, xdata0, ydata0, psfxw0, psfyw0, \n",
    "                                   time, flux, xdata, ydata, psfxw, psfyw, breaks, savepath,\n",
    "                                   showPlot=True)\n",
    "    else:\n",
    "        # plot raw data\n",
    "        make_plots.plot_photometry(time0, flux0, xdata0, ydata0, psfxw0, psfyw0, \n",
    "                                   time, flux, xdata, ydata, psfxw, psfyw, breaks, savepath,\n",
    "                                   peritime, showPlot=True)\n",
    "\n",
    "# Calculate the photon noise limit\n",
    "if oldPhotometry:\n",
    "    # Fix the old, unhelpful units to electrons to compute photon noise limit\n",
    "    sigF_photon_ppm = dh.get_photon_limit_oldData(rootpath, foldername+filename, foldername_aper+filename_aper,\n",
    "                                                  planet, channel, mode, aors, nFrames, ignoreFrames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load archival/custom data and prepare some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the most recent exoplanet archive data, and select the best constrained value for each parameter\n",
    "dh.downloadExoplanetArchive()\n",
    "if planet!='WASP-18b':\n",
    "    p0_obj = dh.loadArchivalData(rootpath, planet, channel)\n",
    "\n",
    "## If you would rather load your own data (e.g. your planet isn't in the exoplanet archive),\n",
    "## you can use the function below. The error parameters are optional inputs, but are required if you want\n",
    "## to put a prior on a parameter.\n",
    "if planet=='WASP-18b':\n",
    "    # The combination of parameters loaded for WASP-18b are not consistent with each other\n",
    "    p0_obj = dh.loadCustomData(rootpath, planet, channel, 0.09716, 3.562, 0.9414526, 2458375.169883,\n",
    "                               84.88, 0.0091, 269, 6431, 4.47, 0.11,\n",
    "                               0.00014, 0.022, 0.000026, 0.0000016, 0.33, 0.00200, 3, 48)\n",
    "# p0_obj = loadCustomData(rootpath, planet, channel, rp, a, per, t0, inc, e, argp, Tstar, logg, feh,\n",
    "#                         rp_err, a_err, t0_err, per_err, inc_err, e_err, argp_err, Tstar_err)\n",
    "\n",
    "# if you want to use the best fit params from a previous MCMC run            \n",
    "if initializeWithOld:\n",
    "    p0_obj = dh.reload_old_fit(path_params, p0_obj)\n",
    "    \n",
    "# makes list of parameters that won't be fitted \n",
    "dparams = helpers.expand_dparams(dparams_input, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the guessed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0, p0_labels, p0_fancyLabels = helpers.get_p0(dparams, p0_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup detector, astrophysical, and full-signal functions and prepare priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the astrophysical function\n",
    "astro_func, astro_labels = freeze.make_lambdafunc(astro_models.ideal_lightcurve, p0_labels,\n",
    "                                                  dparams, p0_obj, debug=debug)\n",
    "astro_inputs = time\n",
    "astro_inputs_full = time_full\n",
    "\n",
    "# Compute an initial guess for the astro model\n",
    "astro_guess = astro_func(astro_inputs, **dict([[label, p0[i]] for i, label in enumerate(p0_labels)\n",
    "                                               if label in astro_labels]))\n",
    "\n",
    "# Get the function that checks whether the lightcurve is positive\n",
    "positivity_func, positivity_labels = freeze.make_lambdafunc(astro_models.check_phase, p0_labels,\n",
    "                                                            np.append(dparams, 'checkPhasePhis'),\n",
    "                                                            p0_obj, debug=debug)\n",
    "\n",
    "# Get all of the detector functions used and freeze any requested parameters\n",
    "detec_funcs = []\n",
    "# Get the names of the fitted parameters for each function\n",
    "detec_labels = []\n",
    "# Get the inputs needed for each detector function\n",
    "detec_inputs = []\n",
    "detec_inputs_full = []\n",
    "if 'poly' in mode.lower():\n",
    "    func = detec_models.detec_model_poly\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append([xdata, ydata, mode])\n",
    "    detec_inputs_full.append([xdata_full, ydata_full, mode])\n",
    "if 'pld' in mode.lower():\n",
    "    func = detec_models.detec_model_PLD\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append([Pnorm, mode])\n",
    "    detec_inputs_full.append([Pnorm_full, mode])\n",
    "if 'bliss' in mode.lower():\n",
    "    func = detec_models.detec_model_bliss\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append(bliss.precompute(flux, xdata, ydata, mode,\n",
    "                                        blissNBin, astro_guess, savepath, plot=True))\n",
    "    detec_inputs_full.append(bliss.precompute(flux_full, xdata_full, ydata_full,\n",
    "                                             blissNBin))\n",
    "if 'gp' in mode.lower():\n",
    "    func = detec_models.detec_model_GP\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append([flux, xdata, ydata, True])\n",
    "    detec_inputs_full.append([flux_full, xdata_full, ydata_full, True])\n",
    "if 'hside' in mode.lower():\n",
    "    for i, brk in enumerate(breaks):\n",
    "        # Set the break points for the heaviside function\n",
    "        p0_obj[f's{i}break'] = brk\n",
    "        dparams = np.append(dparams, [f's{i}break'])\n",
    "        p0_fancyLabels = p0_fancyLabels[p0_labels!=f's{i}break']\n",
    "        p0_labels = p0_labels[p0_labels!=f's{i}break']\n",
    "    for i in range(len(breaks), 5):\n",
    "        p0_fancyLabels = p0_fancyLabels[p0_labels!=f's{i}']\n",
    "        p0_labels = p0_labels[p0_labels!=f's{i}']\n",
    "        p0_fancyLabels = p0_fancyLabels[p0_labels!=f's{i}break']\n",
    "        p0_labels = p0_labels[p0_labels!=f's{i}break']\n",
    "        dparams = np.append(dparams, [f's{i}'])\n",
    "        dparams = np.append(dparams, [f's{i}break'])\n",
    "    func = detec_models.hside\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append(time)\n",
    "    detec_inputs_full.append(time_full)\n",
    "if 'tslope' in mode.lower():\n",
    "    func = detec_models.tslope\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append(time)\n",
    "    detec_inputs_full.append(time_full)\n",
    "if 'psfw' in mode.lower():\n",
    "    func = detec_models.detec_model_PSFW\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append(psfxw, psfyw)\n",
    "    detec_inputs_full.append(psfxw_full, psfyw_full)\n",
    "    \n",
    "if len(detec_funcs)==0:\n",
    "    raise NotImplementedError(f'mode=\\'{mode}\\' is not implemented.')\n",
    "\n",
    "# Put gparams and uparams in the right order and remove any that aren't being fitted\n",
    "gparams = np.array([parm for parm in p0_labels if parm in gparams])\n",
    "uparams_unsorted = np.copy(uparams)\n",
    "uparams = np.array([parm for parm in p0_labels if parm in uparams])\n",
    "uparams_limits = np.array([uparams_limits[np.where(uparams_unsorted==uparams[i])[0][0]]\n",
    "                           for i in range(len(uparams))])\n",
    "\n",
    "gpriorInds = np.array([np.where(p0_labels==gpar)[0][0] for gpar in gparams])\n",
    "upriorInds = np.array([np.where(p0_labels==upar)[0][0] for upar in uparams if upar in p0_labels])\n",
    "if 'gp' in mode.lower():\n",
    "    gammaInd = np.where(p0_labels=='gpAmp')[0][0]\n",
    "else:\n",
    "    gammaInd = None\n",
    "\n",
    "# set up Gaussian priors\n",
    "priors, errs = dh.setup_gpriors(gparams, p0_obj)\n",
    "    \n",
    "# Get the full-signal function that models the astrophysical and detector signals\n",
    "signal_func = detec_models.signal\n",
    "signal_inputs = [p0_labels, astro_func, astro_labels, astro_inputs, detec_funcs, detec_labels, detec_inputs]\n",
    "signal_inputs_full = [p0_labels, astro_func, astro_labels, astro_inputs_full,\n",
    "                      detec_funcs, detec_labels, detec_inputs_full]\n",
    "\n",
    "lnprob_inputs = [flux, mode, p0_labels, signal_func, signal_inputs,\n",
    "                 gpriorInds, priors, errs, upriorInds, uparams_limits, gammaInd,\n",
    "                 positivity_func, positivity_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run initial optimization on detector parameters\n",
    "\n",
    "### Run several gradient descents, short MCMCs, and then gradient descents to allow full burn-in\n",
    "\n",
    "#### Feel free to use your own maximum likelihood method - here we just offer a simple method that should often work. The objective of this step is just to start the final MCMC in a reasonable region of parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if runMCMC and not initializeWithOld:\n",
    "    \n",
    "    p0 = dh.burnIn(p0, p0_labels, mode, astro_func, astro_labels, astro_inputs, signal_func, signal_inputs,\n",
    "                   lnprob_inputs, gparams, gpriorInds, priors, errs, time, flux, breaks, bestfitNbin, \n",
    "                   ncpu, savepath, showPlot=True, nIterScipy=nIterScipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ndim, nwalkers = len(p0), 150\n",
    "\n",
    "if runMCMC:\n",
    "    # get scattered starting points in parameter space\n",
    "    # MUST have the initial spread such that every walker passes the lnprior functions\n",
    "    p0_rel_errs = 1e-4*np.ones_like(p0)\n",
    "    gpriorInds = [np.where(p0_labels==gpar)[0][0] for gpar in gparams]\n",
    "    p0_rel_errs[gpriorInds] = np.array(errs)/np.array(priors)\n",
    "    pos0 = np.array([p0*(1+p0_rel_errs*np.random.randn(ndim))+p0_rel_errs/10.*np.abs(np.random.randn(ndim))\n",
    "                     for i in range(nwalkers)])\n",
    "\n",
    "    # Make sure that all starting positions pass the lnpriors, fix them if they don't\n",
    "    priorlnls = np.array([np.isinf(helpers.lnprob(p_tmp, *lnprob_inputs)) for p_tmp in pos0])\n",
    "    iters = 10\n",
    "    while np.any(priorlnls) and iters>0:\n",
    "        p0_rel_errs /= 1.5\n",
    "        pos0[priorlnls] = np.array([p0*(1+p0_rel_errs*np.random.randn(ndim))\n",
    "                                      +p0_rel_errs/10.*np.abs(np.random.randn(ndim))\n",
    "                                    for i in range(np.sum(priorlnls))])\n",
    "        priorlnls[priorlnls] = np.array([np.isinf(helpers.lnprob(p_tmp, *lnprob_inputs))\n",
    "                                         for p_tmp in pos0[priorlnls]])\n",
    "        iters -= 1\n",
    "    if iters==0 and np.any(priorlnls):\n",
    "        print('Warning: Some of the initial values still fail the lnprior!')\n",
    "        print('The following MCMC will likely not work')\n",
    "\n",
    "    # Run the MCMC\n",
    "    print('Running MCMC')\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        with Pool(ncpu) as pool:\n",
    "            sampler = emcee.EnsembleSampler(nwalkers, ndim, helpers.lnprob, args=lnprob_inputs,\n",
    "                                            a = 2, pool=pool)\n",
    "            pos2, prob, state = sampler.run_mcmc(pos0, np.rint((nBurnInSteps2+nProductionSteps)/nwalkers),\n",
    "                                                 progress=True)\n",
    "    print(\"Mean acceptance fraction: {0:.3f}\".format(np.mean(sampler.acceptance_fraction)))\n",
    "    \n",
    "    # Show the evolution of MCMC walkers\n",
    "    burnInChain = sampler.chain[:,:int(np.rint((nBurnInSteps2)/nwalkers)),:]\n",
    "    fname = savepath+'MCMC_burninWalkers_'+mode+'.pdf'\n",
    "    make_plots.walk_style(burnInChain, p0_fancyLabels, 10, fname, showPlot=True)\n",
    "    \n",
    "    # Get only the production steps\n",
    "    lnprobchain = sampler.get_log_prob(discard=int(np.rint((nBurnInSteps2)/nwalkers))).swapaxes(0,1)\n",
    "    chain = sampler.get_chain(discard=int(np.rint((nBurnInSteps2)/nwalkers))).swapaxes(0,1)\n",
    "\n",
    "    #Saving MCMC Results\n",
    "    pathchain = savepath + 'samplerchain_'+mode+'.npy'\n",
    "    pathlnlchain = savepath + 'samplerlnlchain_'+mode+'.npy'\n",
    "    pathposit = savepath + 'samplerposi_'+mode+'.npy'\n",
    "    pathlnpro = savepath + 'samplerlnpr_'+mode+'.npy'\n",
    "    np.save(pathchain, chain)\n",
    "    np.save(pathlnlchain, lnprobchain)\n",
    "    np.save(pathposit, pos2)\n",
    "    np.save(pathlnpro, prob)   \n",
    "    \n",
    "else:\n",
    "\n",
    "    pathchain = savepath + 'samplerchain_'+mode+'.npy'\n",
    "    pathlnlchain = savepath + 'samplerlnlchain_'+mode+'.npy'\n",
    "    chain = np.load(pathchain)\n",
    "    lnprobchain = np.load(pathlnlchain)\n",
    "    \n",
    "    pathlnpro = savepath + 'samplerlnpr_'+mode+'.npy'\n",
    "    if os.path.exists(pathlnpro):\n",
    "        lnprobability = np.load(pathlnpro)\n",
    "\n",
    "samples = chain.reshape((-1, ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output results from MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0_mcmc, MCMC_Results, residuals = dh.print_MCMC_results(flux, flux_full, chain, lnprobchain, mode, channel,\n",
    "                                                         signal_func, signal_inputs, signal_inputs_full,\n",
    "                                                         p0_labels, p0_obj, astro_func, astro_inputs,\n",
    "                                                         astro_inputs_full, astro_labels, usebestfit, savepath,\n",
    "                                                         sigF_photon_ppm, nFrames, secondOrderOffset,\n",
    "                                                         compFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a plot showing the evolution of the astro parameters\n",
    "ind_a = len(astro_labels) # index where the astro params\n",
    "labels = p0_fancyLabels[np.in1d(p0_labels, astro_labels)]\n",
    "fname = savepath+'MCMC_astroWalkers_'+mode+'.pdf'\n",
    "make_plots.walk_style(chain[:,:,:ind_a], labels, 10, fname, showPlot=True)\n",
    "\n",
    "# Make a plot showing the evolution of the detector parameters\n",
    "if 'bliss' not in mode.lower() or r'$\\sigma_F$' in p0_fancyLabels:\n",
    "    labels = p0_fancyLabels[np.logical_not(np.in1d(p0_labels, astro_labels))]\n",
    "    fname = savepath+'MCMC_detecWalkers_'+mode+'.pdf'\n",
    "    make_plots.walk_style(chain[:,:,ind_a:], labels, 10, fname, showPlot=True)\n",
    "\n",
    "# Make a corner plot for the astro parameters\n",
    "if runMCMC:\n",
    "    labels = p0_fancyLabels[np.in1d(p0_labels, astro_labels)]\n",
    "    fig = corner.corner(samples[:,:ind_a], labels=labels, quantiles=[0.16, 0.5, 0.84], show_titles=True, \n",
    "                        plot_datapoints=True, title_kwargs={\"fontsize\": 12})\n",
    "    plotname = savepath + 'MCMC_corner_'+mode+'.pdf'\n",
    "    fig.savefig(plotname, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out the RAM\n",
    "samples = None\n",
    "sampler = None\n",
    "chain = None\n",
    "lnprobchain = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the final model (best-fit parameters if usebestfit==True, otherwise median of MCMC chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "astroModel = astro_func(astro_inputs, **dict([[label, p0_mcmc[i]] for i, label in enumerate(p0_labels)\n",
    "                                              if label in astro_labels]))\n",
    "signalModel = signal_func(p0_mcmc, *signal_inputs)\n",
    "detecModel = signalModel/astroModel\n",
    "\n",
    "make_plots.plot_model(time, flux, astroModel, detecModel, breaks, savepath, 'Bestfit_'+mode+'.pdf',\n",
    "                      nbin=bestfitNbin, showPlot=True, fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING: these durations assume circular orbits!!!\n",
    "intTime = (time[1]-time[0])\n",
    "ingrDuration = helpers.getIngressDuration(p0_mcmc, p0_labels, p0_obj, intTime)\n",
    "occDuration = helpers.getOccultationDuration(p0_mcmc, p0_labels, p0_obj, intTime)\n",
    "\n",
    "minBins = 5\n",
    "\n",
    "make_plots.plot_rednoise(residuals, minBins, ingrDuration, occDuration, intTime,\n",
    "                         mode, savepath, savetxt=True, showPlot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for residual correlations after fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pld' not in mode.lower():\n",
    "    make_plots.look_for_residual_correlations(time, flux, xdata, ydata, psfxw, psfyw, residuals,\n",
    "                                              p0_mcmc, p0_labels, p0_obj, mode, savepath, showPlot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
