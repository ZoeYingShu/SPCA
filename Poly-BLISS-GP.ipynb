{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats as sp\n",
    "import scipy.optimize as spopt\n",
    "\n",
    "import emcee\n",
    "import batman\n",
    "import corner\n",
    "\n",
    "from astropy import constants as const\n",
    "from astropy import units\n",
    "\n",
    "import numpy as np\n",
    "import time as t\n",
    "import timeit\n",
    "import os, sys\n",
    "import csv\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "import inspect\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import astropy.time\n",
    "from astropy.stats import sigma_clip\n",
    "from astropy.table import Table, Column\n",
    "from astropy.io import fits\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "# SPCA libraries\n",
    "from SPCA import helpers, astro_models, make_plots, make_plots_custom, detec_models, bliss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet = 'MASCARA-1b'\n",
    "channel = 'ch2'\n",
    "mode = 'Poly2_v2'\n",
    "rootpath = '/home/taylor/Documents/Research/spitzer/MEGA/'\n",
    "\n",
    "# parameters you do not wish to fit\n",
    "dparams_input = []#['ecosw','esinw']\n",
    "\n",
    "# parameters you want to place a gaussian prior on\n",
    "gparams = ['t0', 'per', 'a', 'inc']\n",
    "\n",
    "# parameters you want to place a uniform prior on\n",
    "uparams = ['gpLx', 'gpLy']\n",
    "uparams_limits = [[0,-3],[0,-3]]\n",
    "\n",
    "ncpu = 3                                 # The number of cpu threads to be used when running MCMC\n",
    "runMCMC = True                           # whether to run MCMC or just load-in past results\n",
    "nBurnInSteps1 = 1e5                      # number of steps to use for the first mcmc burn-in (only used if not doing GP)\n",
    "nBurnInSteps2 = 1e6                      # number of steps to use for the second mcmc burn-in\n",
    "nProductionSteps = 2e5                   # number of steps to use with mcmc production run\n",
    "usebestfit = False                       # used best-fit instead of most probable parameters \n",
    "blissNBin = 8                            # number of knots to allow in each direction\n",
    "secondOrderOffset = False                # should you use the second order sinusoid terms when calculating offset\n",
    "bestfitNbin = 50                         # the number of binned values to overplot on the bestfit 4-panel figure (use None if you don't want these overplotted)\n",
    "nFrames  = 64                            # number of frames per binned data point\n",
    "initializeWithOld = False                # initial with previous mcmc results using the same method\n",
    "\n",
    "#non-unity if you have dilution by a nearby companion\n",
    "compFactor = 1.\n",
    "\n",
    "######### FIX: REMOVE THIS LATER!!!! ###############\n",
    "# compFactor += 0.8858*0.1196\n",
    "###############################################\n",
    "\n",
    "# non-zero if you want to remove some initial data points\n",
    "cut_tmp = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### FIX: REMOVE THIS LATER!!!! ###############\n",
    "# if 'WASP-12' in planet:\n",
    "#     if 'old' in planet.lower() and channel=='ch1':\n",
    "#         compFactor += 0.9332*0.1149\n",
    "#     elif 'old' in planet.lower() and channel=='ch2':\n",
    "#         compFactor += 0.8382*0.1196\n",
    "#     elif channel=='ch1':\n",
    "#         compFactor += 0.8773*0.1149\n",
    "#     elif channel=='ch2':\n",
    "#         compFactor += 0.8858*0.1196\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rootpath[-1]!='/':\n",
    "    rootpath += '/'\n",
    "\n",
    "\n",
    "with open(rootpath+planet+'/analysis/'+channel+'/cutFirstAOR.txt', 'r') as file:\n",
    "    cutFirstAOR = file.readline().strip()=='True'\n",
    "\n",
    "#Download the most recent masterfile of the best data on each target\n",
    "try:\n",
    "    _ = urllib.request.urlretrieve('http://www.astro.umontreal.ca/~adb/masterfile.ecsv', '../masterfile.ecsv')\n",
    "except:\n",
    "    print('Unable to download the most recent Exoplanet Archive data - resorting to previously downloaded version.')\n",
    "\n",
    "if os.path.exists('../masterfile.ecsv'):\n",
    "    data = Table.to_pandas(Table.read('../masterfile.ecsv'))\n",
    "else:\n",
    "    print('ERROR: No previously downloaded Exoplanet Archive data - try again when you are connected to the internet.')\n",
    "    print(FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), '../masterfile.ecsv'))\n",
    "    exit()\n",
    "\n",
    "names = np.array(data['pl_hostname'])+np.array(data['pl_letter'])\n",
    "names = np.array([name.replace(' ','').replace('-', '').replace('_','') for name in names])\n",
    "\n",
    "\n",
    "# make params obj\n",
    "p0_obj  = helpers.signal_params() \n",
    "\n",
    "# Personalize object default object values\n",
    "p0_obj.name = planet\n",
    "\n",
    "nameIndex = np.where(names==planet.replace(' ','').replace('-', '').split('_')[0])[0][0]\n",
    "\n",
    "if np.isfinite(data['pl_ratror'][nameIndex]):\n",
    "    p0_obj.rp = data['pl_ratror'][nameIndex]\n",
    "else:\n",
    "    p0_obj.rp = data['pl_rads'][nameIndex]/data['st_rad'][nameIndex]\n",
    "\n",
    "if np.isfinite(data['pl_ratdor'][nameIndex]):\n",
    "    p0_obj.a = data['pl_ratdor'][nameIndex]\n",
    "    p0_obj.a_err = np.mean([data['pl_ratdorerr1'][nameIndex],\n",
    "                            -data['pl_ratdorerr2'][nameIndex]])\n",
    "else:\n",
    "    p0_obj.a = data['pl_orbsmax'][nameIndex]*const.au.value/data['st_rad'][nameIndex]/const.R_sun.value\n",
    "    p0_obj.a_err = np.sqrt(\n",
    "        (np.mean([data['pl_orbsmaxerr1'][nameIndex], -data['pl_orbsmaxerr2'][nameIndex]])*const.au.value\n",
    "         /data['st_rad'][nameIndex]/const.R_sun.value)**2\n",
    "        + (data['pl_orbsmax'][nameIndex]*const.au.value\n",
    "           /data['st_rad'][nameIndex]**2/const.R_sun.value\n",
    "           *np.mean([data['st_raderr1'][nameIndex], -data['st_raderr2'][nameIndex]]))**2\n",
    "    )\n",
    "p0_obj.per = data['pl_orbper'][nameIndex]\n",
    "p0_obj.per_err = np.mean([data['pl_orbpererr1'][nameIndex],\n",
    "                          -data['pl_orbpererr2'][nameIndex]])\n",
    "p0_obj.t0 = data['pl_tranmid'][nameIndex]-2.4e6-0.5\n",
    "p0_obj.t0_err = np.mean([data['pl_tranmiderr1'][nameIndex],\n",
    "                         -data['pl_tranmiderr2'][nameIndex]])\n",
    "p0_obj.inc = data['pl_orbincl'][nameIndex]\n",
    "p0_obj.inc_err = np.mean([data['pl_orbinclerr1'][nameIndex],\n",
    "                          -data['pl_orbinclerr2'][nameIndex]])\n",
    "p0_obj.Tstar = data['st_teff'][nameIndex]\n",
    "p0_obj.Tstar_err = np.mean([data['st_tefferr1'][nameIndex],\n",
    "                            -data['st_tefferr2'][nameIndex]])\n",
    "\n",
    "e = data['pl_orbeccen'][nameIndex]\n",
    "argp = data['pl_orblper'][nameIndex]\n",
    "\n",
    "if e != 0:\n",
    "\n",
    "    if not np.isfinite(argp):\n",
    "        print('Randomly generating an argument of periastron...')\n",
    "        argp = np.random.uniform(0.,360.,1)\n",
    "\n",
    "    p0_obj.ecosw = e/np.sqrt(1+np.tan(argp*np.pi/180.)**2)\n",
    "    if 90 < argp < 270:\n",
    "        p0_obj.ecosw*=-1\n",
    "    p0_obj.esinw = np.tan(argp*np.pi/180.)*p0_obj.ecosw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the phoenix file ready to compute the stellar brightness temperature\n",
    "teffStr = p0_obj.Tstar\n",
    "if teffStr <= 7000:\n",
    "    teffStr = teffStr - (teffStr%100) + np.rint((teffStr%100)/100)*100\n",
    "elif teffStr > 7000:\n",
    "    teffStr = teffStr - (teffStr%200) + np.rint((teffStr%200)/200)*200\n",
    "elif teffStr > 12000:\n",
    "    teffStr = 12000\n",
    "teffStr = str(int(teffStr)).zfill(5)\n",
    "\n",
    "logg = data['st_logg'][nameIndex]\n",
    "if np.isnan(logg):\n",
    "    logg = 4.5\n",
    "logg = logg - (logg%0.5) + np.rint((logg%0.5)*2)/2.\n",
    "logg = -logg\n",
    "feh = data['st_metfe'][nameIndex]\n",
    "if np.isnan(feh):\n",
    "    feh = 0.\n",
    "feh = (feh - (feh%0.5) + np.rint((feh%0.5)*2)/2.)\n",
    "if feh<-2.:\n",
    "    feh = (feh - (feh%1) + np.rint((feh%1)))\n",
    "\n",
    "webfolder = 'ftp://phoenix.astro.physik.uni-goettingen.de/HiResFITS/'\n",
    "phoenixPath = rootpath+planet+'/phoenix/'\n",
    "phoenixWavFile = phoenixPath+'WAVE_PHOENIX-ACES-AGSS-COND-2011.fits'\n",
    "if not os.path.exists(phoenixPath):\n",
    "    print('Downloading relevant PHOENIX wavelengths file...')\n",
    "    os.mkdir(phoenixPath)\n",
    "    try:\n",
    "        _ = urllib.request.urlretrieve(webfolder+'WAVE_PHOENIX-ACES-AGSS-COND-2011.fits', phoenixWavFile)\n",
    "    except:\n",
    "        print('ERROR: No previously downloaded PHOENIX data - try again when you are connected to the internet.')\n",
    "        exit()\n",
    "    print('Done download.')\n",
    "\n",
    "webfolder += 'PHOENIX-ACES-AGSS-COND-2011/Z'+(\"{0:+.01f}\".format(feh) if feh!=0 else '-0.0')+'/'\n",
    "\n",
    "webfile = ('lte'+teffStr\n",
    "         +(\"{0:+.02f}\".format(logg) if logg!=0 else '-0.00')\n",
    "         +(\"{0:+.01f}\".format(feh) if feh!=0 else '-0.0')\n",
    "         +'.PHOENIX-ACES-AGSS-COND-2011-HiRes.fits')\n",
    "\n",
    "phoenixSpectraFile = phoenixPath+webfile\n",
    "\n",
    "if not os.path.exists(phoenixSpectraFile):\n",
    "    print('Downloading relevant PHOENIX spectra...')\n",
    "    try:\n",
    "        _ = urllib.request.urlretrieve(webfolder+webfile, phoenixSpectraFile)\n",
    "    except:\n",
    "        print('ERROR: No previously downloaded PHOENIX data - try again when you are connected to the internet.')\n",
    "        exit()\n",
    "    print('Done download.')\n",
    "\n",
    "\n",
    "# set up Gaussian priors\n",
    "priors = []\n",
    "errs = []\n",
    "if 't0' in gparams:\n",
    "    priors.append(p0_obj.t0)\n",
    "    errs.append(p0_obj.t0_err)\n",
    "if 'per' in gparams:\n",
    "    priors.append(p0_obj.per)\n",
    "    errs.append(p0_obj.per_err)\n",
    "if 'a' in gparams:\n",
    "    priors.append(p0_obj.a)\n",
    "    errs.append(p0_obj.a_err)\n",
    "if 'inc' in gparams:\n",
    "    priors.append(p0_obj.inc)\n",
    "    errs.append(p0_obj.inc_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOR_snip = ''\n",
    "with open(rootpath+planet+'/analysis/aorSnippet.txt') as f:\n",
    "    AOR_snip = f.readline().strip()\n",
    "\n",
    "mainpath   = rootpath+planet+'/analysis/'+channel+'/'\n",
    "phoption = ''\n",
    "ignoreFrames = np.array([])\n",
    "rms = None\n",
    "with open(mainpath+'bestPhOption.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        if phoption=='' and lines[i][0]=='/':\n",
    "            foldername = rootpath+lines[i][lines[i].find(planet):].strip()+'/'\n",
    "            phoption = lines[i].split('/')[-1].strip()\n",
    "            i += 1\n",
    "            ignoreFrames = np.array(lines[i].strip().split('=')[1].replace(' ','').split(','))\n",
    "            if np.all(ignoreFrames==['']):\n",
    "                ignoreFrames = np.array([]).astype(int)\n",
    "            else:\n",
    "                ignoreFrames = ignoreFrames.astype(int)\n",
    "            i += 1\n",
    "            rms = float(lines[i])\n",
    "        elif phoption!='' and lines[i][0]=='/':\n",
    "            if float(lines[i+2]) < rms:\n",
    "                foldername = rootpath+lines[i][lines[i].find(planet):].strip()+'/'\n",
    "                phoption = lines[i].split('/')[-1].strip()\n",
    "                i += 1\n",
    "                ignoreFrames = np.array(lines[i].split('=')[1].replace(' ','').split(','))\n",
    "                if np.all(ignoreFrames==['']):\n",
    "                    ignoreFrames = np.array([]).astype(int)\n",
    "                else:\n",
    "                    ignoreFrames = ignoreFrames.astype(int)\n",
    "                i += 1\n",
    "                rms = float(lines[i])\n",
    "            else:\n",
    "                i += 3\n",
    "\n",
    "# labels for all the possible fit parameters\n",
    "p0_names = np.array(['t0', 'per', 'rp', 'a', 'inc', 'ecosw', 'esinw', 'q1', 'q2', 'fp', \n",
    "                     'A', 'B', 'C', 'D', 'r2', 'r2off', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7',\n",
    "                     'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'c15', 'c16', 'c17',\n",
    "                     'c18', 'c19', 'c20', 'c21', 'd1', 'd2', 'd3', 's1', 's2', 'm1',\n",
    "                     'gpAmp', 'gpLx', 'gpLy', 'sigF'])\n",
    "\n",
    "# fancy labels for plot purposed  for all possible fit parameters\n",
    "p0_fancyNames = np.array([r'$t_0$', r'$P_{\\rm orb}$', r'$R_p/R_*$', r'$a/R_*$', r'$i$', r'$e \\cos(\\omega)$',\n",
    "                          r'$e \\sin(\\omega)$', r'$q_1$', r'$q_2$', r'$f_p$', r'$A$', r'$B$',\n",
    "                          r'$C$', r'$D$', r'$R_{p,2}/R_*$', r'$R_{p,2}/R_*$ Offset', r'$C_1$', r'$C_2$', r'$C_3$',\n",
    "                          r'$C_4$', r'$C_5$', r'$C_6$', r'$C_7$', r'$C_8$', r'$C_9$',\n",
    "                          r'$C_{10}$', r'$C_{11}$', r'$C_{12}$', r'$C_{13}$', r'$C_{14}$',\n",
    "                          r'$C_{15}$', r'$C_{16}$', r'$C_{17}$', r'$C_{18}$', r'$C_{19}$',\n",
    "                          r'$C_{20}$', r'$C_{21}$',r'$D_1$', r'$D_2$', r'$D_3$', r'$S_1$', r'$S_2$', r'$M_1$',\n",
    "                          r'$GP_{amp}$', r'$GP_{Lx}$', r'$GP_{Ly}$', r'$\\sigma_F$'])\n",
    "\n",
    "gparams_unsorted = np.copy(gparams)\n",
    "gparams = np.array([parm for parm in p0_names if parm in gparams])\n",
    "\n",
    "uparams_unsorted = np.copy(uparams)\n",
    "uparams = np.array([parm for parm in p0_names if parm in uparams])\n",
    "\n",
    "\n",
    "# path where outputs are saved\n",
    "savepath   = foldername + mode + '/'\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "\n",
    "aors = os.listdir(rootpath+planet+'/data/'+channel)\n",
    "aors = np.sort([aor for aor in aors if AOR_snip==aor[:len(AOR_snip)]])\n",
    "AOR_snip = AOR_snip[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# path to photometry outputs\n",
    "filename   = channel + '_datacube_binned_AORs'+AOR_snip+'.dat'\n",
    "filenamef  = channel + '_datacube_full_AORs'+AOR_snip+'.dat'\n",
    "# Path to previous mcmc results (optional)\n",
    "path_params = foldername + mode + '/ResultMCMC_'+mode+'_Params.npy'\n",
    "\n",
    "# For datasets where the first AOR is peak-up data\n",
    "if cutFirstAOR:\n",
    "    rawfiles = np.sort(os.listdir(rootpath+planet+'/data/'+channel+'/'+aors[0]+'/'+channel+'/bcd/'))\n",
    "    rawfiles  = [rawfile for rawfile in rawfiles if '_bcd.fits' in rawfile]\n",
    "    cut = cut_tmp+len(rawfiles)\n",
    "else:\n",
    "    cut = cut_tmp\n",
    "\n",
    "breaks = []\n",
    "for aor in aors:\n",
    "    rawfiles = np.sort(os.listdir(rootpath+planet+'/data/'+channel+'/'+aor+'/'+channel+'/bcd/'))\n",
    "    rawfiles  = [rawfile for rawfile in rawfiles if '_bcd.fits' in rawfile]\n",
    "    rawImage = fits.open(rootpath+planet+'/data/'+channel+'/'+aor+'/'+channel+'/bcd/'+rawfiles[0])\n",
    "\n",
    "    # Get the time of the first exposure of each AOR after the first\n",
    "    #     - this allows us to plot dashed lines where AOR breaks happen and where jump discontinuities happen\n",
    "    breaks.append(rawImage[0].header['BMJD_OBS'] + rawImage[0].header['FRAMTIME']/2/3600/24)\n",
    "    rawHeader = rawImage[0].header\n",
    "    rawImage.close()\n",
    "breaks = np.sort(breaks)[1:]\n",
    "\n",
    "# Calculate the photon noise limit\n",
    "flux = np.loadtxt(foldername+filename, usecols=[0], skiprows=1)     # mJr/str\n",
    "flux *= rawHeader['GAIN']*rawHeader['EXPTIME']/rawHeader['FLUXCONV']\n",
    "sigF_photon_ppm = 1/np.sqrt(np.median(flux))/np.sqrt(64-len(ignoreFrames))*1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signalfunc = detec_models.signal\n",
    "\n",
    "if 'poly' in mode.lower():\n",
    "    detecfunc = detec_models.detec_model_poly\n",
    "elif 'bliss' in mode.lower():\n",
    "    detecfunc = detec_models.detec_model_bliss\n",
    "elif 'gp' in mode.lower():\n",
    "    detecfunc = detec_models.detec_model_GP\n",
    "else:\n",
    "    raise NotImplementedError('Only polynomial, BLISS, and GP models are currently implemented! \\nmode=\\''+mode+'\\' does not include \\'poly\\', \\'Poly\\', \\'bliss\\', \\'BLISS\\', \\'gp\\', or \\'GP\\'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading full data set for BIC calculation afterwards\n",
    "data_full = helpers.get_full_data(foldername, filenamef)\n",
    "\n",
    "# sigma clip the data\n",
    "flux_full, fluxerr_full, time_full, xdata_full, ydata_full, psfxw_full, psfyw_full = helpers.clip_full_data(*data_full, nFrames, cut, ignoreFrames)\n",
    "mid_x_full, mid_y_full = np.nanmean(xdata_full), np.nanmean(ydata_full)\n",
    "\n",
    "# Get Data\n",
    "data = helpers.get_data(foldername+filename)\n",
    "# Sort data\n",
    "flux0, flux_err0, time0, xdata0, ydata0, psfxw0, psfyw0 = helpers.time_sort_data(*data)\n",
    "# Trim AOR\n",
    "flux, flux_err, time, xdata, ydata, psfxw, psfyw = helpers.time_sort_data(*data, cut=cut)\n",
    "# pre-calculation\n",
    "mid_x, mid_y = np.mean(xdata), np.mean(ydata)\n",
    "\n",
    "\n",
    "## FIX: peritime doesn't get made\n",
    "if True:#'ecosw' in dparams_input and 'esinw' in dparams_input:\n",
    "    # make photometry plots\n",
    "    make_plots.plot_photometry(time0, flux0, xdata0, ydata0, psfxw0, psfyw0, \n",
    "                    time, flux, xdata, ydata, psfxw, psfyw, breaks, savepath)\n",
    "    plt.close()\n",
    "else:\n",
    "    # plot raw data\n",
    "    make_plots.plot_photometry(time0, flux0, xdata0, ydata0, psfxw0, psfyw0, \n",
    "                    time, flux, xdata, ydata, psfxw, psfyw, breaks, savepath, peritime)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare where the heaviside break occurs\n",
    "if 'hside' in mode.lower():\n",
    "    p0_obj.s2 = timeaor1\n",
    "    dparams = np.append(dparams, ['s2'])\n",
    "\n",
    "\n",
    "# redefining the zero centroid position\n",
    "if 'bliss' not in mode.lower():\n",
    "    xdata -= mid_x\n",
    "    ydata -= mid_y\n",
    "    xdata_full -= mid_x_full\n",
    "    ydata_full -= mid_y_full\n",
    "\n",
    "# True if user wants details about the lambda functions created\n",
    "debug = False\n",
    "\n",
    "# makes list of parameters that won't be fitted \n",
    "dparams = helpers.expand_dparams(dparams_input, mode)  \n",
    "\n",
    "# if you want to use the best fit params from a previous MCMC run\n",
    "if initializeWithOld:\n",
    "    Table_par = np.load(path_params)                  # table of best-fit params from prev. run\n",
    "    index     = np.in1d(p0_names, dparams)            # get the index list of params to be fitted\n",
    "    nparams   = p0_names[np.where(index==False)[0]]   # get the name list of params to be fitted\n",
    "    for name in nparams:\n",
    "        cmd = 'p0_obj.' + name + ' = ' + 'Table_par[\\'' + name + '\\'][0]'\n",
    "        try:\n",
    "            exec(cmd)\n",
    "        except Exception as e:\n",
    "            print(\"type error: \" + str(e))            # catch errors if you use values from fun with less params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "# get p0\n",
    "obj = p0_obj\n",
    "p0, p0_labels, p0_fancyLabels = helpers.get_p0(p0_names, p0_fancyNames, dparams, p0_obj)\n",
    "\n",
    "# make lambda function\n",
    "signalfunc = helpers.make_lambdafunc(signalfunc, dparams, p0_obj, debug=debug)\n",
    "if debug:\n",
    "    print()\n",
    "\n",
    "# making lambda function for phasecurve and detector\n",
    "astrofunc = helpers.make_lambdafunc(astro_models.ideal_lightcurve, dparams, p0_obj, debug=debug)\n",
    "if debug:\n",
    "    print()\n",
    "\n",
    "detecfunc = helpers.make_lambdafunc(detecfunc, dparams, p0_obj, debug=debug)\n",
    "if debug:\n",
    "    print()\n",
    "\n",
    "psfwifunc = helpers.make_lambdafunc(detec_models.detec_model_PSFW, dparams, p0_obj, debug=debug)\n",
    "if debug:\n",
    "    print()\n",
    "\n",
    "hsidefunc = helpers.make_lambdafunc(detec_models.hside, dparams, p0_obj, debug=debug)\n",
    "if debug:\n",
    "    print()\n",
    "\n",
    "tslopefunc = helpers.make_lambdafunc(detec_models.tslope, dparams, p0_obj, debug=debug)\n",
    "if debug:\n",
    "    print()\n",
    "\n",
    "# make a lnprior lambda function\n",
    "lnpriorfunc = helpers.make_lambdafunc(helpers.lnprior, dparams, obj=p0_obj, debug=debug)\n",
    "\n",
    "if gparams != [] or uparams != []:\n",
    "    def lnprior_custom_gaussian_helper(p0, priorInds, priors, errs):\n",
    "        prior = 0\n",
    "        for i in range(len(priorInds)):\n",
    "            prior -= 0.5*(((p0[priorInds[i]] - priors[i])/errs[i])**2.)\n",
    "        return prior\n",
    "\n",
    "    def lnprior_custom_uniform_helper(p0, priorInds, limits):\n",
    "        if priorInds == []:\n",
    "            return 0\n",
    "        elif np.any(np.logical_or(np.array(uparams_limits)[:,0] < p0[priorInds],\n",
    "                                np.array(uparams_limits)[:,1] > p0[priorInds])):\n",
    "            return -np.inf\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def lnprior_custom_gamma_helper(p0, priorInd, shape, rate):\n",
    "        if priorInd is not None:\n",
    "            x = np.exp(p0[priorInd])\n",
    "            alpha = shape\n",
    "            beta = rate\n",
    "            return np.log(beta**alpha * x**(alpha-1) * np.exp(-beta*x) / np.math.factorial(alpha-1))\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    gpriorInds = [np.where(p0_labels==gpar)[0][0] for gpar in gparams]\n",
    "    upriorInds = [np.where(p0_labels==upar)[0][0] for upar in uparams if upar in p0_labels]\n",
    "    if 'gp' in mode.lower():\n",
    "        gammaInd = np.where(p0_labels=='gpAmp')[0][0]\n",
    "    else:\n",
    "        gammaInd = None\n",
    "    lnprior_custom = lambda p0: (lnprior_custom_gaussian_helper(p0, gpriorInds, priors, errs)+\n",
    "                                 lnprior_custom_uniform_helper(p0, upriorInds, uparams_limits)+\n",
    "                                 lnprior_custom_gamma_helper(p0, gammaInd, 1, 100))\n",
    "else:\n",
    "    lnprior_custom = None\n",
    "\n",
    "# detemining which params in p0 is part of ideal_lightcurve, detec, psfw\n",
    "p0_astro  = inspect.getargspec(astro_models.ideal_lightcurve).args[1:]\n",
    "p0_asval, p0_astro, p0_astroFancy  = helpers.get_p0(p0_astro, p0_fancyNames, dparams,p0_obj)\n",
    "\n",
    "if 'bliss' not in mode.lower():\n",
    "    p0_detec  = inspect.getargspec(detecfunc).args[1:]\n",
    "    p0_deval, p0_detec, p0_detecFancy  = helpers.get_p0(p0_detec, p0_fancyNames, dparams,p0_obj)\n",
    "else:\n",
    "    if 'sigF' in dparams:\n",
    "        p0_detec = []\n",
    "        p0_detecFancy = []\n",
    "        p0_deval = p0_obj.sigF\n",
    "    else:\n",
    "        p0_detec = p0_labels[-1]\n",
    "        p0_detecFancy = p0_fancyLabels[-1]\n",
    "        p0_deval = p0[-1]\n",
    "\n",
    "p0_psfwi  = inspect.getargspec(detec_models.detec_model_PSFW).args[1:]\n",
    "p0_psval, p0_psfwi, p0_psfwiFancy  = helpers.get_p0(p0_psfwi, p0_fancyNames, dparams,p0_obj)\n",
    "\n",
    "p0_hside  = inspect.getargspec(detec_models.hside).args[1:]\n",
    "p0_hsval, p0_hside, p0_hsideFancy  = helpers.get_p0(p0_hside, p0_fancyNames, dparams,p0_obj)\n",
    "\n",
    "p0_tslope  = inspect.getargspec(detec_models.tslope).args[1:]\n",
    "p0_tsval, p0_tslope, p0_tslopeFancy  = helpers.get_p0(p0_tslope, p0_fancyNames, dparams,p0_obj)\n",
    "\n",
    "\n",
    "# initial astro model\n",
    "astro_guess = astrofunc(time, *p0_asval)\n",
    "resid       = flux/astro_guess\n",
    "\n",
    "if 'bliss' in mode.lower():\n",
    "    make_plots.plot_centroids(xdata0, ydata0, xdata, ydata, savepath)\n",
    "\n",
    "    signal_inputs = bliss.precompute(flux, time, xdata, ydata, psfxw, psfyw, mode,\n",
    "                                     astro_guess, blissNBin, savepath)\n",
    "elif 'gp' in mode.lower():\n",
    "    signal_inputs = [flux, time, xdata, ydata, psfxw, psfyw, mode]\n",
    "    detec_inputs = [flux, xdata, ydata, time, True, astro_guess]\n",
    "elif 'pld' in mode.lower():\n",
    "    #Something will need to go here\n",
    "    print('PLD not yet implemented!')\n",
    "elif 'poly' in mode.lower():# and 'psfw' in mode.lower():\n",
    "    signal_inputs = [flux, time, xdata, ydata, psfxw, psfyw, mode]\n",
    "    detec_inputs = [xdata, ydata, mode]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run initial optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If not GP, Run initial optimization on just the detector parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a first fit on the detector parameters to get into the right ballpark\n",
    "if runMCMC:\n",
    "    if not initializeWithOld and 'bliss' not in mode.lower() and 'gp' not in mode.lower():\n",
    "        spyFunc0 = lambda p0_temp, inputs: np.mean((resid-detecfunc(inputs, *p0_temp))**2)\n",
    "        spyResult0 = scipy.optimize.minimize(spyFunc0, p0[np.where(np.in1d(p0_labels,p0_detec))], detec_inputs, 'Nelder-Mead')\n",
    "\n",
    "        # replace p0 with new detector coefficient values\n",
    "        if spyResult0.success:\n",
    "            p0[np.where(np.in1d(p0_labels,p0_detec))] = spyResult0.x\n",
    "            resid /= detecfunc(detec_inputs, *p0[np.where(np.in1d(p0_labels,p0_detec))])\n",
    "\n",
    "\n",
    "\n",
    "        # 2) get initial guess for psfw model\n",
    "        if 'psfw' in mode.lower():\n",
    "            spyFunc0 = lambda p0_temp: np.mean((resid-psfwifunc([psfxw, psfyw], *p0_temp))**2)\n",
    "            spyResult0 = scipy.optimize.minimize(spyFunc0, p0[np.where(np.in1d(p0_labels,p0_psfwi))], method='Nelder-Mead')\n",
    "\n",
    "            # replace p0 with new detector coefficient values\n",
    "            if spyResult0.success:\n",
    "                p0[np.where(np.in1d(p0_labels,p0_psfwi))] = spyResult0.x\n",
    "                resid /= psfwifunc([psfxw, psfyw], *p0[np.where(np.in1d(p0_labels,p0_psfwi))])\n",
    "\n",
    "        # 3) get initial guess for hside model\n",
    "        if 'hside' in mode.lower():\n",
    "            spyFunc0 = lambda p0_temp: np.mean((resid-hsidefunc(time, *p0_temp))**2)\n",
    "            spyResult0 = scipy.optimize.minimize(spyFunc0, p0[np.where(np.in1d(p0_labels,p0_hside))], method='Nelder-Mead')\n",
    "\n",
    "            # replace p0 with new detector coefficient values\n",
    "            if spyResult0.success:\n",
    "                p0[np.where(np.in1d(p0_labels,p0_hside))] = spyResult0.x\n",
    "                resid /= hsidefunc(time, *p0[np.where(np.in1d(p0_labels,p0_hside))])\n",
    "\n",
    "        if 'tslope' in mode.lower():\n",
    "            spyFunc0 = lambda p0_temp: np.mean((resid-tslopefunc(time, *p0_temp))**2)\n",
    "            spyResult0 = scipy.optimize.minimize(spyFunc0, p0[np.where(np.in1d(p0_labels,p0_tslope))], method='Nelder-Mead')\n",
    "\n",
    "            # replace p0 with new detector coefficient values\n",
    "            if spyResult0.success:\n",
    "                p0[np.where(np.in1d(p0_labels,p0_tslope))] = spyResult0.x\n",
    "                resid /= tslopefunc(time, *p0[np.where(np.in1d(p0_labels,p0_tslope))])\n",
    "\n",
    "\n",
    "        # initial guess\n",
    "        signal_guess = signalfunc(signal_inputs, *p0)\n",
    "        #includes psfw and/or hside functions if they're being fit\n",
    "        detec_full_guess = signal_guess/astro_guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If GP, run initial full optimization to find best location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runMCMC and 'gp' in mode.lower():\n",
    "    checkPhasePhis = np.linspace(-np.pi,np.pi,1000)\n",
    "\n",
    "    initial_lnprob = helpers.lnprob(p0, signalfunc, lnpriorfunc, signal_inputs, checkPhasePhis, lnprior_custom)\n",
    "\n",
    "    spyFunc_full = lambda p0_temp, inputs: -helpers.lnprob(p0_temp, *inputs)\n",
    "\n",
    "    nIterScipy = 10\n",
    "    \n",
    "    final_lnprob = -np.inf\n",
    "    p0_optimized = []\n",
    "    p0_temps = []\n",
    "    print('Running iterative scipy.optimize')\n",
    "    from tqdm import tqdm\n",
    "    for i in tqdm(range(nIterScipy)):\n",
    "        p0_rel_errs = 1e-1*np.ones_like(p0)\n",
    "        gpriorInds = [np.where(p0_labels==gpar)[0][0] for gpar in gparams]\n",
    "        p0_rel_errs[gpriorInds] = np.array(errs)/np.array(priors)\n",
    "        p0_temp = p0*(1+p0_rel_errs*np.random.randn(len(p0)))+p0_rel_errs/10.*np.abs(np.random.randn(len(p0)))\n",
    "\n",
    "        p0_temp[p0_labels=='A'] = np.random.uniform(0.,0.3)\n",
    "        p0_temp[p0_labels=='B'] = np.random.uniform(-0.2,0.2)\n",
    "        # Assignment to non-existent indices is safe (safelt ignores it), so this is fine for all modes\n",
    "        p0_temp[p0_labels=='C'] = np.random.uniform(-0.3,0.3)\n",
    "        p0_temp[p0_labels=='D'] = np.random.uniform(-0.3,0.3)\n",
    "        p0_temp[p0_labels=='gpAmp'] = np.random.uniform(-4,-6)\n",
    "        p0_temp[p0_labels=='gpLx'] = np.random.uniform(-0.5,-1)\n",
    "        p0_temp[p0_labels=='gpLy'] = np.random.uniform(-0.5,-1)\n",
    "\n",
    "        spyResult_full = scipy.optimize.minimize(spyFunc_full, p0_temp, [signalfunc, lnpriorfunc, signal_inputs, checkPhasePhis, lnprior_custom], 'Nelder-Mead')\n",
    "        lnprob_temp = helpers.lnprob(spyResult_full.x, signalfunc, lnpriorfunc, signal_inputs, checkPhasePhis, lnprior_custom)\n",
    "\n",
    "        p0_temps.append(np.copy(spyResult_full.x))\n",
    "\n",
    "        if np.isfinite(lnprob_temp) and lnprob_temp > final_lnprob:\n",
    "            final_lnprob = lnprob_temp\n",
    "            p0_optimized = np.copy(spyResult_full.x)\n",
    "\n",
    "            if final_lnprob > initial_lnprob:\n",
    "                print('Improved ln-likelihood!')\n",
    "                print(\"ln-likelihood: {0:.2f}\".format(final_lnprob))\n",
    "                p0 = np.copy(p0_optimized)\n",
    "\n",
    "    astro_guess = astrofunc(time, *p0[np.where(np.in1d(p0_labels,p0_astro))])\n",
    "    signal_guess = signalfunc(signal_inputs, *p0)\n",
    "    #includes psfw and/or hside functions if they're being fit\n",
    "    detec_full_guess = signal_guess/astro_guess\n",
    "\n",
    "    # plot detector initial guess\n",
    "    make_plots.plot_init_guess(time, flux, astro_guess, detec_full_guess)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If GP, run an MCMC centred at the location of each optimization to break free of local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runMCMC and 'gp' in mode.lower():\n",
    "    print('Running first burn-ins')\n",
    "    p0_temps_mcmc = []\n",
    "    for p0_temp in p0_temps:\n",
    "        ndim = len(p0)\n",
    "        nwalkers = ndim*3\n",
    "        nBurnInSteps1 = 25500 # Chosen to give 500 steps per walker for Poly2v1 and 250 steps per walker for Poly5v2\n",
    "\n",
    "        # get scattered starting point in parameter space \n",
    "        # MUST HAVE THE INITIAL SPREAD SUCH THAT EVERY SINGLE WALKER PASSES lnpriorfunc AND lnprior_custom\n",
    "        p0_rel_errs = 1e-3*np.ones_like(p0_temp)\n",
    "        gpriorInds = [np.where(p0_labels==gpar)[0][0] for gpar in gparams]\n",
    "        p0_rel_errs[gpriorInds] = np.array(errs)/np.array(priors)\n",
    "        pos0 = np.array([p0_temp*(1+p0_rel_errs*np.random.randn(ndim))+p0_rel_errs/10.*np.abs(np.random.randn(ndim)) for i in range(nwalkers)])\n",
    "\n",
    "        checkPhasePhis = np.linspace(-np.pi,np.pi,1000)\n",
    "\n",
    "        #sampler\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, ndim, helpers.lnprob, a = 2,\n",
    "                                        args=(signalfunc, lnpriorfunc, \n",
    "                                              signal_inputs, checkPhasePhis, lnprior_custom))\n",
    "\n",
    "        priorlnls = np.array([(lnpriorfunc(*p_tmp, mode, checkPhasePhis) != 0.0 or (lnprior_custom != 'none' and np.isinf(lnprior_custom(p_tmp)))) for p_tmp in pos0])\n",
    "        iters = 10\n",
    "        while np.any(priorlnls) and iters>0:\n",
    "    #         print('Warning: Some of the initial values fail the lnprior!')\n",
    "    #         print('Trying to re-draw positions...')\n",
    "            p0_rel_errs /= 1.5\n",
    "            pos0[priorlnls] = np.array([p0*(1+p0_rel_errs*np.random.randn(ndim))+p0_rel_errs/10.*np.abs(np.random.randn(ndim)) for i in range(np.sum(priorlnls))])\n",
    "            priorlnls = np.array([(lnpriorfunc(*p_tmp, mode, checkPhasePhis) != 0.0 or (lnprior_custom != 'none' and np.isinf(lnprior_custom(p_tmp)))) for p_tmp in pos0])\n",
    "            iters -= 1\n",
    "        if iters==0 and np.any(priorlnls):\n",
    "            print('Warning: Some of the initial values still fail the lnprior and the following MCMC will likely not work!')\n",
    "\n",
    "        #Second burn-in\n",
    "        #Do quick burn-in to get walkers spread out\n",
    "        tic = t.time()\n",
    "        pos1, prob, state = sampler.run_mcmc(pos0, np.rint(nBurnInSteps1/nwalkers), progress=False)\n",
    "        print('Mean burn-in acceptance fraction: {0:.3f}'\n",
    "                        .format(np.median(sampler.acceptance_fraction)))\n",
    "        # sampler.reset()\n",
    "        toc = t.time()\n",
    "        print('MCMC runtime = %.2f min\\n' % ((toc-tic)/60.))\n",
    "\n",
    "        p0_temps_mcmc.append(np.copy(sampler.flatchain[np.argmax(sampler.flatlnprobability)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If GP, run a final optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runMCMC and 'gp' in mode.lower():\n",
    "    checkPhasePhis = np.linspace(-np.pi,np.pi,1000)\n",
    "\n",
    "    initial_lnprob = helpers.lnprob(p0, signalfunc, lnpriorfunc, signal_inputs, checkPhasePhis, lnprior_custom)\n",
    "\n",
    "    spyFunc_full = lambda p0_temp, inputs: -helpers.lnprob(p0_temp, *inputs)\n",
    "\n",
    "    final_lnprob = -np.inf\n",
    "    p0_optimized = []\n",
    "    p0_temps_final = []\n",
    "    print('Running second iterative scipy.optimize')\n",
    "    from tqdm import tqdm\n",
    "    for p0_temp in tqdm(p0_temps_mcmc):\n",
    "\n",
    "        spyResult_full = scipy.optimize.minimize(spyFunc_full, p0_temp, [signalfunc, lnpriorfunc, signal_inputs, checkPhasePhis, lnprior_custom], 'Nelder-Mead')\n",
    "        lnprob_temp = helpers.lnprob(spyResult_full.x, signalfunc, lnpriorfunc, signal_inputs, checkPhasePhis, lnprior_custom)\n",
    "\n",
    "        p0_temps_final.append(np.copy(spyResult_full.x))\n",
    "\n",
    "        if np.isfinite(lnprob_temp) and lnprob_temp > final_lnprob:\n",
    "            final_lnprob = lnprob_temp\n",
    "            p0_optimized = np.copy(spyResult_full.x)\n",
    "\n",
    "            if final_lnprob > initial_lnprob:\n",
    "                print('Improved ln-likelihood!')\n",
    "                print(\"ln-likelihood: {0:.2f}\".format(final_lnprob))\n",
    "                p0 = np.copy(p0_optimized)\n",
    "\n",
    "    # if np.isfinite(final_lnprob) and final_lnprob > initial_lnprob:\n",
    "    #     print('The full scipy optimize worked:')\n",
    "    #     print(\"Initial ln-likelihood: {0:.2f}\".format(initial_lnprob))\n",
    "    #     print(\"Final ln-likelihood: {0:.2f}\".format(final_lnprob))\n",
    "\n",
    "    #     p0 = np.copy(p0_optimized)\n",
    "\n",
    "    astro_guess = astrofunc(time, *p0[np.where(np.in1d(p0_labels,p0_astro))])\n",
    "    signal_guess = signalfunc(signal_inputs, *p0)\n",
    "    #includes psfw and/or hside functions if they're being fit\n",
    "    detec_full_guess = signal_guess/astro_guess\n",
    "    \n",
    "    make_plots.plot_init_guess(time, flux, astro_guess, detec_full_guess)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If not a GP, run a first MCMC burn-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if runMCMC and 'gp' not in mode.lower():\n",
    "    ndim, nwalkers = len(p0), 150\n",
    "    \n",
    "    # get scattered starting point in parameter space \n",
    "    # MUST HAVE THE INITIAL SPREAD SUCH THAT EVERY SINGLE WALKER PASSES lnpriorfunc AND lnprior_custom\n",
    "    p0_rel_errs = 1e-4*np.ones_like(p0)\n",
    "    gpriorInds = [np.where(p0_labels==gpar)[0][0] for gpar in gparams]\n",
    "    p0_rel_errs[gpriorInds] = np.array(errs)/np.array(priors)\n",
    "    pos0 = np.array([p0*(1+p0_rel_errs*np.random.randn(ndim))+p0_rel_errs/10.*np.abs(np.random.randn(ndim)) for i in range(nwalkers)])\n",
    "\n",
    "    checkPhasePhis = np.linspace(-np.pi,np.pi,1000)\n",
    "\n",
    "    def templnprob(pars):\n",
    "        return helpers.lnprob(pars, signalfunc, lnpriorfunc, signal_inputs, checkPhasePhis, lnprior_custom)\n",
    "    \n",
    "    priorlnls = np.array([(lnpriorfunc(*p_tmp, mode, checkPhasePhis) != 0.0 or (lnprior_custom != 'none' and np.isinf(lnprior_custom(p_tmp)))) for p_tmp in pos0])\n",
    "    iters = 10\n",
    "    while np.any(priorlnls) and iters>0:\n",
    "    #         print('Warning: Some of the initial values fail the lnprior!')\n",
    "    #         print('Trying to re-draw positions...')\n",
    "        p0_rel_errs /= 1.5\n",
    "        pos0[priorlnls] = np.array([p0*(1+p0_rel_errs*np.random.randn(ndim))+p0_rel_errs/10.*np.abs(np.random.randn(ndim)) for i in range(np.sum(priorlnls))])\n",
    "        priorlnls = np.array([(lnpriorfunc(*p_tmp, mode, checkPhasePhis) != 0.0 or (lnprior_custom != 'none' and np.isinf(lnprior_custom(p_tmp)))) for p_tmp in pos0])\n",
    "        iters -= 1\n",
    "    if iters==0 and np.any(priorlnls):\n",
    "        print('Warning: Some of the initial values still fail the lnprior and the following MCMC will likely not work!')\n",
    "\n",
    "        \n",
    "        \n",
    "    #First burn-in\n",
    "    tic = t.time()\n",
    "    print('Running first burn-in')\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        with Pool(ncpu) as pool:\n",
    "            #sampler\n",
    "            sampler = emcee.EnsembleSampler(nwalkers, ndim, templnprob, a = 2, pool=pool)\n",
    "            pos1, prob, state = sampler.run_mcmc(pos0, np.rint(nBurnInSteps1/nwalkers), progress=True)\n",
    "    print('Mean burn-in acceptance fraction: {0:.3f}'\n",
    "                .format(np.median(sampler.acceptance_fraction)))\n",
    "    \n",
    "    \n",
    "    fname = savepath+'MCMC_'+mode+'_burnin1Walkers.pdf'\n",
    "    helpers.walk_style(len(p0), nwalkers, sampler.chain, 10, int(np.rint(nBurnInSteps1/nwalkers)), p0_fancyLabels)\n",
    "    plt.savefig(fname)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    p0 = sampler.flatchain[np.argmax(sampler.flatlnprobability)]\n",
    "    astro_guess = astrofunc(time, *p0[np.where(np.in1d(p0_labels,p0_astro))])\n",
    "    signal_guess = signalfunc(signal_inputs, *p0)\n",
    "    #includes psfw and/or hside functions if they're being fit\n",
    "    detec_full_guess = signal_guess/astro_guess\n",
    "    make_plots.plot_init_guess(time, flux, astro_guess, detec_full_guess)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runMCMC:\n",
    "    checkPhasePhis = np.linspace(-np.pi,np.pi,1000)\n",
    "\n",
    "    number = int(1e3)\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        avgRuntime = timeit.timeit(lambda: helpers.lnprob(p0, signalfunc, lnpriorfunc, signal_inputs, checkPhasePhis, lnprior_custom), number=number)/float(number)\n",
    "    estRuntime = avgRuntime*(nBurnInSteps2+nProductionSteps)/60.\n",
    "    print('Estimated total MCMC runtime: ~'+str(int(np.rint(estRuntime)))+' mins/cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers = len(p0), 150\n",
    "\n",
    "if runMCMC:\n",
    "    # get scattered starting point in parameter space \n",
    "    # MUST HAVE THE INITIAL SPREAD SUCH THAT EVERY SINGLE WALKER PASSES lnpriorfunc AND lnprior_custom\n",
    "    p0_rel_errs = 1e-4*np.ones_like(p0)\n",
    "    gpriorInds = [np.where(p0_labels==gpar)[0][0] for gpar in gparams]\n",
    "    p0_rel_errs[gpriorInds] = np.array(errs)/np.array(priors)\n",
    "    pos0 = np.array([p0*(1+p0_rel_errs*np.random.randn(ndim))+p0_rel_errs/10.*np.abs(np.random.randn(ndim)) for i in range(nwalkers)])\n",
    "\n",
    "    checkPhasePhis = np.linspace(-np.pi,np.pi,1000)\n",
    "\n",
    "    def templnprob(pars):\n",
    "        return helpers.lnprob(pars, signalfunc, lnpriorfunc, signal_inputs, checkPhasePhis, lnprior_custom)\n",
    "\n",
    "    priorlnls = np.array([(lnpriorfunc(*p_tmp, mode, checkPhasePhis) != 0.0 or (lnprior_custom != 'none' and np.isinf(lnprior_custom(p_tmp)))) for p_tmp in pos0])\n",
    "    iters = 10\n",
    "    while np.any(priorlnls) and iters>0:\n",
    "    #         print('Warning: Some of the initial values fail the lnprior!')\n",
    "    #         print('Trying to re-draw positions...')\n",
    "        p0_rel_errs /= 1.5\n",
    "        pos0[priorlnls] = np.array([p0*(1+p0_rel_errs*np.random.randn(ndim))+p0_rel_errs/10.*np.abs(np.random.randn(ndim)) for i in range(np.sum(priorlnls))])\n",
    "        priorlnls = np.array([(lnpriorfunc(*p_tmp, mode, checkPhasePhis) != 0.0 or (lnprior_custom != 'none' and np.isinf(lnprior_custom(p_tmp)))) for p_tmp in pos0])\n",
    "        iters -= 1\n",
    "    if iters==0 and np.any(priorlnls):\n",
    "        print('Warning: Some of the initial values still fail the lnprior and the following MCMC will likely not work!')\n",
    "\n",
    "    #Second burn-in\n",
    "    #Do quick burn-in to get walkers spread out\n",
    "    tic = t.time()\n",
    "    print('Running second burn-in')\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        with Pool(ncpu) as pool:\n",
    "            #sampler\n",
    "            sampler = emcee.EnsembleSampler(nwalkers, ndim, templnprob, a = 2, pool=pool)\n",
    "            pos1, prob, state = sampler.run_mcmc(pos0, np.rint(nBurnInSteps2/nwalkers), progress=True)\n",
    "    print('Mean burn-in acceptance fraction: {0:.3f}'\n",
    "                    .format(np.median(sampler.acceptance_fraction)))\n",
    "    fname = savepath+'MCMC_'+mode+'_burninWalkers.pdf'\n",
    "    helpers.walk_style(len(p0), nwalkers, sampler.chain, 10, int(np.rint(nBurnInSteps2/nwalkers)), p0_fancyLabels, fname)\n",
    "    sampler.reset()\n",
    "    toc = t.time()\n",
    "    print('MCMC runtime = %.2f min\\n' % ((toc-tic)/60.))\n",
    "\n",
    "\n",
    "    #Run production\n",
    "    #Run that will be saved\n",
    "    tic = t.time()\n",
    "    # Continue from last positions and run production\n",
    "    print('Running production')\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        with Pool(ncpu) as pool:\n",
    "            #sampler\n",
    "            sampler = emcee.EnsembleSampler(nwalkers, ndim, templnprob, a = 2, pool=pool)\n",
    "            pos2, prob, state = sampler.run_mcmc(pos1, np.rint(nProductionSteps/nwalkers), progress=True)\n",
    "    print(\"Mean acceptance fraction: {0:.3f}\"\n",
    "                    .format(np.mean(sampler.acceptance_fraction)))\n",
    "    toc = t.time()\n",
    "    print('MCMC runtime = %.2f min\\n' % ((toc-tic)/60.))\n",
    "\n",
    "\n",
    "    #Saving MCMC Results\n",
    "    pathchain = savepath + 'samplerchain_'+mode+'.npy'\n",
    "    pathposit = savepath + 'samplerposi_'+mode+'.npy'\n",
    "    pathlnpro = savepath + 'samplerlnpr_'+mode+'.npy'\n",
    "    np.save(pathchain, sampler.chain)\n",
    "    np.save(pathposit, pos2)\n",
    "    np.save(pathlnpro, prob)\n",
    "\n",
    "    chain = sampler.chain\n",
    "    \n",
    "else:\n",
    "\n",
    "    pathchain = savepath + 'samplerchain_'+mode+'.npy'\n",
    "    chain = np.load(pathchain)\n",
    "    pathlnpro = savepath + 'samplerlnpr_'+mode+'.npy'\n",
    "    if os.path.exists(pathlnpro):\n",
    "        lnprobability = np.load(pathlnpro)\n",
    "\n",
    "samples = chain.reshape((-1, ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output results from MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'inc' in p0_labels:\n",
    "    pos_inc = np.where(p0_labels == 'inc')[0][0]\n",
    "    samples[np.where(samples[:,pos_inc] > 90)[0],pos_inc] = 180 - samples[np.where(samples[:,pos_inc] > 90)[0],pos_inc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the results\n",
    "\n",
    "(MCMC_Results) = np.array(list(map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]), zip(*np.percentile(samples, [16, 50, 84],axis=0)))))\n",
    "p0_mcmc = np.median(samples, axis=0)\n",
    "\n",
    "# taking max lnprob params instead of median bc degeneracy\n",
    "if usebestfit == True: \n",
    "    if runMCMC == True:\n",
    "        maxk, maxiter = np.unravel_index((sampler.lnprobability).argmax(), (sampler.lnprobability).shape)\n",
    "        p0_mcmc = sampler.chain[maxk, maxiter,:]\n",
    "    else:\n",
    "        maxk, maxiter = np.unravel_index((lnprobability).argmax(), (lnprobability).shape)\n",
    "        p0_mcmc = chain[maxk, maxiter,:]\n",
    "    for i in range(len(p0_mcmc)):\n",
    "        MCMC_Results[i] = (p0_mcmc[i], MCMC_Results[i][1], MCMC_Results[i][2])\n",
    "\n",
    "# adjust fp, sigF, rp, r2 for dilution due to any nearby companion\n",
    "if np.any(p0_labels == 'fp'):\n",
    "    for i in range(3):\n",
    "        MCMC_Results[np.where(p0_labels == 'fp')[0][0]][i] *= compFactor\n",
    "if np.any(p0_labels == 'sigF'):\n",
    "    for i in range(3):\n",
    "        MCMC_Results[np.where(p0_labels == 'sigF')[0][0]][i] *= compFactor\n",
    "if np.any(p0_labels == 'rp'):\n",
    "    for i in range(3):\n",
    "        MCMC_Results[np.where(p0_labels == 'rp')[0][0]][i] *= np.sqrt(compFactor)\n",
    "if np.any(p0_labels == 'r2'):\n",
    "    for i in range(3):\n",
    "        MCMC_Results[np.where(p0_labels == 'r2')[0][0]][i] *= np.sqrt(compFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing output from MCMC\n",
    "out = \"MCMC result:\\n\\n\"\n",
    "for i in range(len(p0)):\n",
    "    out += '{:>8} = {:>16}  +{:>16}  -{:>16}\\n'.format(p0_labels[i],MCMC_Results[i][0], MCMC_Results[i][1], MCMC_Results[i][2])\n",
    "\n",
    "# getting and printing the phase offset\n",
    "As = samples[:,np.where(p0_labels == 'A')[0][0]][:,np.newaxis]\n",
    "Bs = samples[:,np.where(p0_labels == 'B')[0][0]][:,np.newaxis]\n",
    "phis = np.linspace(-np.pi,np.pi,1000)\n",
    "offsets = []\n",
    "stepSizeOffsets = int(1e2)\n",
    "if ('A' in p0_labels)  and ('B' in p0_labels) and (('C' not in p0_labels and 'D' not in p0_labels) or not secondOrderOffset):\n",
    "    for i in range(int(len(As)/stepSizeOffsets)):\n",
    "        offsets.extend(-phis[np.argmax(1 + As[i*stepSizeOffsets:(i+1)*stepSizeOffsets]*(np.cos(phis)-1) + Bs[i*stepSizeOffsets:(i+1)*stepSizeOffsets]*np.sin(phis),axis=1)]*180/np.pi)\n",
    "    if len(As)%stepSizeOffsets != 0:\n",
    "        offsets.extend(-phis[np.argmax(1 + As[-len(As)%stepSizeOffsets:]*(np.cos(phis)-1) + Bs[-len(As)%stepSizeOffsets:]*np.sin(phis),axis=1)]*180/np.pi)\n",
    "    offset = np.percentile(np.array(offsets), [16, 50, 84])[[1,2,0]]\n",
    "    offset[1] -= offset[0]\n",
    "    offset[2] = offset[0]-offset[2]\n",
    "    out += '{:>8} = {:>16}  +{:>16}  -{:>16} degrees east\\n'.format('Offset', offset[0], offset[1], offset[2])\n",
    "elif ('A' in p0_labels)  and ('B' in p0_labels) and ('C' in p0_labels) and ('D' in p0_labels):\n",
    "    Cs = samples[:,np.where(p0_labels == 'C')[0][0]][:,np.newaxis]\n",
    "    Ds = samples[:,np.where(p0_labels == 'D')[0][0]][:,np.newaxis]\n",
    "    for i in range(int(len(As)/stepSizeOffsets)):\n",
    "        offsets.extend(-phis[np.argmax(1 + As[i*stepSizeOffsets:(i+1)*stepSizeOffsets]*(np.cos(phis)-1) + Bs[i*stepSizeOffsets:(i+1)*stepSizeOffsets]*np.sin(phis) + Cs[i*stepSizeOffsets:(i+1)*stepSizeOffsets]*(np.cos(2*phis)-1) + Ds[i*stepSizeOffsets:(i+1)*stepSizeOffsets]*np.sin(2*phis),axis=1)]*180/np.pi)\n",
    "    if len(As)%stepSizeOffsets != 0:\n",
    "        offsets.extend(-phis[np.argmax(1 + As[-len(As)%stepSizeOffsets:]*(np.cos(phis)-1) + Bs[-len(As)%stepSizeOffsets:]*np.sin(phis),axis=1)]*180/np.pi)\n",
    "    offset = np.percentile(np.array(offsets), [16, 50, 84])[[1,2,0]]\n",
    "    offset[1] -= offset[0]\n",
    "    offset[2] = offset[0]-offset[2]\n",
    "    out += '{:>8} = {:>16}  +{:>16}  -{:>16} degrees east\\n'.format('Offset', offsets[0], offsets[1], offsets[2])\n",
    "\n",
    "# print the R2/Rp ratio\n",
    "if ('ellipse' in mode.lower()) and ('rp' in p0_labels) and ('r2' in p0_labels):\n",
    "    out += '{:>8} = {:>16}\\n'.format('R2/Rp', p0_mcmc[np.where(p0_labels == 'r2')[0][0]]/p0_mcmc[np.where(p0_labels == 'rp')[0][0]])\n",
    "\n",
    "if channel == 'ch1':\n",
    "    wav = 3.6*1e-6\n",
    "elif channel == 'ch2':\n",
    "    wav = 4.5*1e-6\n",
    "if 'fp' in p0_labels:\n",
    "    fp_MCMC = samples[:,np.where(p0_labels == 'fp')[0][0]]*compFactor\n",
    "else:\n",
    "    fp_MCMC = p0_obj['fp']\n",
    "if 'rp' in p0_labels:\n",
    "    rp_MCMC = samples[:,np.where(p0_labels == 'rp')[0][0]]*np.sqrt(compFactor)\n",
    "else:\n",
    "    rp_MCMC = p0_obj['rp']\n",
    "\n",
    "\n",
    "\n",
    "f = fits.open(phoenixSpectraFile)\n",
    "fStar = f[0].data*1e-1 # 'erg/s/cm^2/cm' to kg/s^3\n",
    "f.close()\n",
    "f = fits.open(phoenixWavFile)\n",
    "wavStar = f[0].data*1e-4 # angstrom to micron\n",
    "f.close()\n",
    "\n",
    "def planck(wav, T):\n",
    "    intensity = (2.0*const.h.value*const.c.value**2) / ((wav**5) * (np.exp(const.h.value*const.c.value/(wav*const.k_B.value*T)) - 1.0))\n",
    "    return intensity\n",
    "def fluxDiff(temp, fStarSummed, wavs):\n",
    "    #factor of pi likely needed to account for emitting area (pi*rstar^2 where rstar=1)\n",
    "    return (np.sum(planck(wavs, temp)*np.pi)-fStarSummed)**2\n",
    "temps = np.linspace(5500, 7000, 500)\n",
    "if channel == 'ch1':\n",
    "    incides = np.where(np.logical_and(wavStar < 4., wavStar > 3.))[0]\n",
    "else:\n",
    "    incides = np.where(np.logical_and(wavStar < 5., wavStar > 4.))[0]\n",
    "diffs = [fluxDiff(temp, np.sum(fStar[incides]), wavStar[incides]*1e-6) for temp in temps]\n",
    "tstar_b = temps[np.argmin(diffs)]\n",
    "\n",
    "tday = const.h.value*const.c.value/(const.k_B.value*wav)*(np.log(1+(np.exp(const.h.value*const.c.value/(const.k_B.value*wav*tstar_b))-1)/(fp_MCMC/rp_MCMC**2)))**-1\n",
    "tnight = const.h.value*const.c.value/(const.k_B.value*wav)*(np.log(1+(np.exp(const.h.value*const.c.value/(const.k_B.value*wav*tstar_b))-1)/(fp_MCMC*(1-2*As[:,0])/rp_MCMC**2)))**-1\n",
    "\n",
    "out += '{:>8} = {:>16}  +{:>16}  -{:>16}\\n'.format('T Day: ', np.median(tday), np.percentile(tday, 84)-np.median(tday), np.median(tday)-np.percentile(tday, 16))\n",
    "out += '{:>8} = {:>16}  +{:>16}  -{:>16}\\n'.format('T Night: ', np.nanmedian(tnight), np.nanpercentile(tnight, 84)-np.nanmedian(tnight), np.nanmedian(tnight)-np.nanpercentile(tnight, 16))\n",
    "out += 'For T_{*,b} = '+str(tstar_b)+'\\n'\n",
    "\n",
    "print(out)\n",
    "with open(savepath+'MCMC_RESULTS_'+mode+'.txt','w') as file:\n",
    "    file.write(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p0[p0_labels=='A'] == 0.207\n",
    "# p0[p0_labels=='B'] == -0.119\n",
    "# p0[p0_labels=='C'] == -0.445\n",
    "# p0[p0_labels=='D'] == 0.191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_a = len(p0_astro) # index where the astro params end\n",
    "labels = p0_fancyLabels[:ind_a]\n",
    "\n",
    "fname = savepath+'MCMC_'+mode+'_astroWalkers.pdf'\n",
    "helpers.walk_style(ind_a, nwalkers, chain, 10, chain.shape[1], labels, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'bliss' not in mode.lower() or 'sigF' not in dparams:\n",
    "    labels = p0_fancyLabels[ind_a:]\n",
    "    fname = savepath+'MCMC_'+mode+'_detecWalkers.pdf'\n",
    "    helpers.walk_style(len(p0)-ind_a, nwalkers, chain[:,:,ind_a:], 10, chain.shape[1], labels, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runMCMC:\n",
    "    fig = corner.corner(samples[:,:ind_a], labels=p0_fancyLabels, quantiles=[0.16, 0.5, 0.84], show_titles=True, \n",
    "                        plot_datapoints=True, title_kwargs={\"fontsize\": 12})\n",
    "    plotname = savepath + 'MCMC_'+mode+'_corner.pdf'\n",
    "    fig.savefig(plotname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ecosw' in p0_labels and 'esinw' in p0_labels:\n",
    "    '''Eccentricity and Longitude of Periastron Coefficient'''\n",
    "\n",
    "    ind1 = np.where(p0_labels == 'ecosw')[0][0]\n",
    "    ind2 = np.where(p0_labels == 'esinw')[0][0]\n",
    "    e_chain = np.sqrt(samples[:,ind1]**2 + samples[:,ind2]**2)\n",
    "    w_chain = np.arctan2(samples[:,ind2], samples[:,ind1]) #np.arctan(samples[:,ind2]/samples[:,ind1])\n",
    "    binse = np.linspace(np.min(e_chain), np.max(e_chain), 20)\n",
    "    binsw = np.linspace(np.min(w_chain), np.max(w_chain), 20)\n",
    "\n",
    "    fig, axes = plt.subplots(ncols = 2, nrows = 2, figsize = (8,6))\n",
    "    axes[0,0].hist(samples[:,ind1], bins=np.linspace(np.min(samples[:,ind1]), np.max(samples[:,ind1]), 20), color='k', alpha=0.3)\n",
    "    axes[0,1].hist(samples[:,ind2], bins=np.linspace(np.min(samples[:,ind2]), np.max(samples[:,ind2]), 20), color='k', alpha=0.3)\n",
    "    axes[1,0].hist(e_chain, binse, color='k', alpha=0.3)\n",
    "    axes[1,1].hist(w_chain, binsw, color='k', alpha=0.3)\n",
    "\n",
    "    plt.setp(axes[0,0].get_yticklabels(), visible=False)\n",
    "    plt.setp(axes[0,1].get_yticklabels(), visible=False)\n",
    "    plt.setp(axes[1,0].get_yticklabels(), visible=False)\n",
    "    plt.setp(axes[1,1].get_yticklabels(), visible=False)\n",
    "\n",
    "    plt.setp(axes[0,0].get_xticklabels(), rotation = 45)\n",
    "    plt.setp(axes[0,1].get_xticklabels(), rotation = 45)\n",
    "    plt.setp(axes[1,0].get_xticklabels(), rotation = 45)\n",
    "    plt.setp(axes[1,1].get_xticklabels(), rotation = 45)\n",
    "\n",
    "    axes[0,0].set_title('$e \\cos (\\omega)$', fontsize=12)\n",
    "    axes[0,1].set_title('$e \\sin (\\omega)$', fontsize=12)\n",
    "    axes[1,0].set_title('$e$', fontsize=12)\n",
    "    axes[1,1].set_title('$\\omega$', fontsize=12)\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    fig.subplots_adjust(wspace=0.2)\n",
    "    plotname = savepath + 'MCMC_'+mode+'_ecc-omega.pdf'\n",
    "    fig.savefig(plotname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'q1' in p0_labels and 'q2' in p0_labels:\n",
    "    '''Stellar Limb Darkening Parameters'''\n",
    "\n",
    "    ind1 = np.where(p0_labels == 'q1')[0][0]\n",
    "    ind2 = np.where(p0_labels == 'q2')[0][0]\n",
    "    u1_chain = 2*np.sqrt(samples[:,ind1]**2)*samples[:,ind2]\n",
    "    u2_chain = np.sqrt(samples[:,ind1]**2)*(1-2*samples[:,ind2])\n",
    "    binsu1 = np.linspace(np.min(u1_chain), np.max(u1_chain), 20)\n",
    "    binsu2 = np.linspace(np.min(u2_chain), np.max(u2_chain), 20)\n",
    "\n",
    "    fig, axes = plt.subplots(ncols = 2, nrows = 2, figsize = (8,6))\n",
    "    axes[0,0].hist(samples[:,ind1], bins=np.linspace(np.min(samples[:,ind1]), np.max(samples[:,ind1]), 20), color='k', alpha=0.3)\n",
    "    axes[0,1].hist(samples[:,ind2], bins=np.linspace(np.min(samples[:,ind2]), np.max(samples[:,ind2]), 20), color='k', alpha=0.3)\n",
    "    axes[1,0].hist(u1_chain, binsu1, color='k', alpha=0.3)\n",
    "    axes[1,1].hist(u2_chain, binsu2, color='k', alpha=0.3)\n",
    "\n",
    "    plt.setp(axes[0,0].get_yticklabels(), visible=False)\n",
    "    plt.setp(axes[0,1].get_yticklabels(), visible=False)\n",
    "    plt.setp(axes[1,0].get_yticklabels(), visible=False)\n",
    "    plt.setp(axes[1,1].get_yticklabels(), visible=False)\n",
    "\n",
    "    plt.setp(axes[0,0].get_xticklabels(), rotation = 45)\n",
    "    plt.setp(axes[0,1].get_xticklabels(), rotation = 45)\n",
    "    plt.setp(axes[1,0].get_xticklabels(), rotation = 45)\n",
    "    plt.setp(axes[1,1].get_xticklabels(), rotation = 45)\n",
    "\n",
    "    axes[0,0].set_title('$q_1$', fontsize=12)\n",
    "    axes[0,1].set_title('$q_2$', fontsize=12)\n",
    "    axes[1,0].set_title('$u_1$', fontsize=12)\n",
    "    axes[1,1].set_title('$u_2$', fontsize=12)\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    fig.subplots_adjust(wspace=0.2)\n",
    "    plotname = savepath + 'MCMC_'+mode+'_limbdark.pdf'\n",
    "    fig.savefig(plotname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = None\n",
    "sampler = None\n",
    "chain = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate uniformly spaced time array for plot purposes\n",
    "time2 = np.linspace(np.min(time), np.max(time), 1000)\n",
    "\n",
    "# generate the models from best-fit parameters\n",
    "mcmc_signal = signalfunc(signal_inputs, *p0_mcmc)\n",
    "mcmc_lightcurve = astrofunc(time, *p0_mcmc[:ind_a])\n",
    "mcmc_detec = mcmc_signal/mcmc_lightcurve\n",
    "\n",
    "#for higher-rez red curve\n",
    "mcmc_lightplot  = astrofunc(time2, *p0_mcmc[:ind_a])\n",
    "\n",
    "\n",
    "# Differences from eccentricity\n",
    "# if 'ecosw' in dparams and 'esinw' in dparams:\n",
    "#     # converting time into orbital phases\n",
    "#     if 't0' in p0_labels:\n",
    "#         t0MCMC = p0_mcmc[np.where(p0_labels == 't0')[0][0]]\n",
    "#     else:\n",
    "#         t0MCMC = p0_obj.t0\n",
    "#     if 'per' in p0_labels:\n",
    "#         perMCMC = p0_mcmc[np.where(p0_labels == 'per')[0][0]]\n",
    "#     else:\n",
    "#         perMCMC = p0_obj.per\n",
    "#     x = (time-t0MCMC)/perMCMC\n",
    "#     orbNum = int(np.min(x))\n",
    "#     if np.min(x)>0:\n",
    "#         orbNum += 1\n",
    "#     x -= orbNum\n",
    "# \n",
    "#     orb_breaks = np.empty(len(breaks))\n",
    "#     for j in range(len(breaks)):\n",
    "#         orb_breaks[j] = ((breaks[j]-t0MCMC)/perMCMC-orbNum)      \n",
    "# else:\n",
    "#     x       = time - peritime\n",
    "#     xbreaks = breaks - peritime\n",
    "\n",
    "# FIX: peritime isn't defined, so just using time for all plots for now\n",
    "orb_breaks = breaks\n",
    "if True:#'ecosw' in dparams and 'esinw' in dparams:\n",
    "    make_plots.plot_bestfit(time, flux, mcmc_lightcurve, mcmc_detec, mode, orb_breaks, savepath, nbin=bestfitNbin, fontsize=24)\n",
    "    plt.close()\n",
    "else:\n",
    "    # FIX: make this default plotting option\n",
    "    make_plots_custom.plot_bestfit(x, flux, mcmc_lightcurve, mcmc_detec, \n",
    "                                   mode, xbreaks, savepath, peritime=0, nbin=bestfitNbin)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if McCubed is installed\n",
    "try:\n",
    "    from mc3.stats import time_avg\n",
    "    intTime = (time[1]-time[0])\n",
    "    minBins = 5\n",
    "    residuals = flux/mcmc_detec - mcmc_lightcurve\n",
    "\n",
    "    #WARNING: these durations assume circular orbits!!!\n",
    "    ingrDuration = helpers.getIngressDuration(p0_mcmc, p0_labels, p0_obj, intTime)\n",
    "    occDuration = helpers.getOccultationDuration(p0_mcmc, p0_labels, p0_obj, intTime)\n",
    "\n",
    "    make_plots.plot_rednoise(residuals, minBins, ingrDuration, occDuration, intTime, mode, savepath, savetxt=True)\n",
    "    plt.close()\n",
    "except ImportError:\n",
    "    #Noise vs bin-size to look for red noise\n",
    "    residuals = flux/mcmc_detec - mcmc_lightcurve\n",
    "\n",
    "    sigmas = []\n",
    "    for i in range(3,len(residuals)):\n",
    "        sigmas.append(helpers.binnedNoise(time,residuals,i))\n",
    "    sigmas = np.array(sigmas)\n",
    "\n",
    "    n_binned = len(residuals)/np.arange(3,len(residuals))\n",
    "\n",
    "    #In case there is a NaN or something while binning\n",
    "    n_binned = n_binned[np.where(np.isfinite(sigmas))[0]]\n",
    "    sigmas = sigmas[np.where(np.isfinite(sigmas))[0]]\n",
    "\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    if 'sigF' in p0_labels:\n",
    "        sigFMCMC = p0_mcmc[np.where(p0_labels == 'sigF')[0][0]]\n",
    "    else:\n",
    "        sigFMCMC = p0_obj.sigF\n",
    "    if 'rp' in p0_labels:\n",
    "        rpMCMC = p0_mcmc[np.where(p0_labels == 'rp')[0][0]]\n",
    "    else:\n",
    "        rpMCMC = p0_obj.rp\n",
    "    if 'a' in p0_labels:\n",
    "        aMCMC = p0_mcmc[np.where(p0_labels == 'a')[0][0]]\n",
    "    else:\n",
    "        aMCMC = p0_obj.a\n",
    "    if 'per' in p0_labels:\n",
    "        perMCMC = p0_mcmc[np.where(p0_labels == 'per')[0][0]]\n",
    "    else:\n",
    "        perMCMC = p0_obj.per\n",
    "\n",
    "    #FIX: WARNING: these durations assume circular orbits!!!\n",
    "    eclDuration = (2*rpMCMC/(2*np.pi*aMCMC/perMCMC))/((time[1]-time[0])) #Eclipse/transit ingress time\n",
    "    trDuration = (2/(2*np.pi*aMCMC/perMCMC))/((time[1]-time[0])) #Transit/eclipse duration\n",
    "\n",
    "    ax.plot(n_binned, sigmas, c='black', label='Data')\n",
    "    ax.plot([n_binned[-1],n_binned[0]], [sigFMCMC, sigFMCMC/np.sqrt(n_binned[0])], c='red', label='White Noise')\n",
    "    ylim = ax.get_ylim()\n",
    "    plt.plot([eclDuration,eclDuration],ylim, color='black', ls='--', alpha=0.6)\n",
    "    plt.plot([trDuration,trDuration],ylim, color='black', ls='-.', alpha=0.6)\n",
    "    ax.set_ylim(ylim)\n",
    "    plt.ylabel(r'$\\sigma$ (ppm)', fontsize='x-large')\n",
    "    plt.xlabel(r'N$_{\\rm binned}$', fontsize='x-large')\n",
    "    plt.legend(loc='best', fontsize='large')\n",
    "    plotname = savepath + 'MCMC_'+mode+'_RedNoise.pdf'\n",
    "    plt.savefig(plotname, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    #Figure out how much red noise we have\n",
    "\n",
    "    #Eclipse Duration\n",
    "    sreal = sigmas[np.where(n_binned<=eclDuration)[0][0]]*1e6\n",
    "    s0 = sigFMCMC/np.sqrt(n_binned[np.where(n_binned<=eclDuration)[0][0]])*1e6\n",
    "    outStr = 'Over Ingress ('+str(round(eclDuration*((time[1]-time[0]))*24*60, 1))+' min):\\n'\n",
    "    outStr += 'Expected Noise (ppm)\\t'+'Observed Noise (ppm)\\n'\n",
    "    outStr += str(s0)+'\\t'+str(sreal)+'\\n'\n",
    "    outStr += 'Observed/Expected\\n'\n",
    "    outStr += str(sreal/s0)+'\\n\\n'\n",
    "    #Transit Duration\n",
    "    sreal = sigmas[np.where(n_binned<=trDuration)[0][0]]*1e6\n",
    "    s0 = sigFMCMC/np.sqrt(n_binned[np.where(n_binned<=trDuration)[0][0]])*1e6\n",
    "    outStr += 'Over Transit/Eclipse ('+str(round(trDuration*((time[1]-time[0]))*24*60, 1))+' min):\\n'\n",
    "    outStr += 'Expected Noise (ppm)\\t'+'Observed Noise (ppm)\\n'\n",
    "    outStr += str(s0)+'\\t'+str(sreal)+'\\n'\n",
    "    outStr += 'Observed/Expected\\n'\n",
    "    outStr += str(sreal/s0)\n",
    "\n",
    "    print(outStr)\n",
    "    with open(plotname[:-3]+'txt','w') as file:\n",
    "        file.write(outStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binned data\n",
    "data = flux/mcmc_detec\n",
    "astro  = mcmc_lightcurve\n",
    "if 'sigF' in p0_labels:\n",
    "    sigFMCMC = p0_mcmc[np.where(p0_labels == 'sigF')[0][0]]\n",
    "else:\n",
    "    sigFMCMC = p0_obj.sigF\n",
    "if 'bliss' in mode.lower():\n",
    "    nKnotsUsed = len(signal_inputs[-4][signal_inputs[-2]])\n",
    "    ndim_eff = ndim+nKnotsUsed\n",
    "else:\n",
    "    ndim_eff = ndim\n",
    "chisB = helpers.chi2(data, astro, sigFMCMC)\n",
    "logLB = helpers.loglikelihood(data, astro, sigFMCMC)\n",
    "EB = helpers.evidence(logLB, ndim, len(data))\n",
    "BICB = -2*EB\n",
    "\n",
    "out = \"\"\"Binned data:\n",
    "chi2 = {0}\n",
    "chi2datum = {1}\n",
    "Likelihood = {2}\n",
    "Evidence = {3}\n",
    "BIC = {4}\"\"\".format(chisB, chisB/len(flux), logLB, EB, BICB)\n",
    "\n",
    "if 'gp' not in mode.lower():\n",
    "    #Unbinned data\n",
    "    '''Get model'''\n",
    "    astro_full   = astrofunc(time_full, *p0_mcmc[:ind_a])\n",
    "    if 'bliss' in mode.lower():\n",
    "        signal_inputs_full = bliss.precompute(flux_full, time_full, xdata_full, ydata_full,\n",
    "                                              psfxw_full, psfyw_full, mode,\n",
    "                                              astro_full, blissNBin, savepath, False)\n",
    "    elif 'pld' in mode.lower():\n",
    "        #Something will need to go here\n",
    "        print('PLD not yet implemented!')\n",
    "    elif 'gp' in mode.lower():\n",
    "        signal_inputs_full = [flux_full, time_full, xdata_full, ydata_full, psfxw_full, psfyw_full, mode]\n",
    "    elif 'poly' in mode.lower():# and 'psfw' in mode.lower():\n",
    "        signal_inputs_full = (flux_full, time_full, xdata_full, ydata_full, psfxw_full, psfyw_full, mode)\n",
    "\n",
    "    signal_full = signalfunc(signal_inputs_full, *p0_mcmc)\n",
    "    detec_full = signal_full/astro_full\n",
    "    data_full = flux_full/detec_full\n",
    "\n",
    "    '''Get Fitted Uncertainty'''\n",
    "    ferr_full = sigFMCMC*np.sqrt(nFrames)\n",
    "\n",
    "    N = len(data_full)\n",
    "    if 'bliss' in mode.lower():\n",
    "        nKnotsUsed_full = len(signal_inputs_full[-4][signal_inputs_full[-2]])\n",
    "        ndim_eff_full = ndim+nKnotsUsed_full\n",
    "    else:\n",
    "        ndim_eff_full = ndim\n",
    "\n",
    "    chis = helpers.chi2(data_full, astro_full, ferr_full)\n",
    "    logL = helpers.loglikelihood(data_full, astro_full, ferr_full)\n",
    "    E = helpers.evidence(logL, ndim_eff_full, N)\n",
    "    BIC = -2*E\n",
    "\n",
    "    out += \"\"\"\n",
    "\n",
    "Unbinned data:\n",
    "chi2 = {0}\n",
    "chi2datum = {1}\n",
    "Likelihood = {2}\n",
    "Evidence = {3}\n",
    "BIC = {4}\"\"\".format(chis, chis/len(xdata_full), logL, E, BIC)\n",
    "\n",
    "with open(savepath+'EVIDENCE_'+mode+'.txt','w') as file:\n",
    "    file.write(out)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultMCMC_Params = Table()\n",
    "\n",
    "for i in range(len(p0_labels)):\n",
    "    ResultMCMC_Params[p0_labels[i]] = MCMC_Results[i]\n",
    "\n",
    "ResultMCMC_Params['offset'] = offset\n",
    "ResultMCMC_Params['tDay'] = [np.nanmedian(tday), np.nanpercentile(tday, 84)-np.nanmedian(tday), np.nanmedian(tday)-np.nanpercentile(tday, 16)]\n",
    "ResultMCMC_Params['tNight'] = [np.nanmedian(tnight), np.nanpercentile(tnight, 84)-np.nanmedian(tnight), np.nanmedian(tnight)-np.nanpercentile(tnight, 16)]\n",
    "\n",
    "ResultMCMC_Params['chi2B'] = [chisB]\n",
    "ResultMCMC_Params['chi2datum'] = [chisB/len(flux)]\n",
    "ResultMCMC_Params['logLB'] = [logLB]\n",
    "ResultMCMC_Params['evidenceB'] = [EB]\n",
    "ResultMCMC_Params['sigF_photon_ppm'] = [sigF_photon_ppm]\n",
    "\n",
    "if 'gp' not in mode.lower():\n",
    "    ResultMCMC_Params['chi2'] = [chis]\n",
    "    ResultMCMC_Params['logL'] = [logL]\n",
    "    ResultMCMC_Params['evidence'] = [E]\n",
    "\n",
    "pathres = savepath + 'ResultMCMC_'+mode+'_Params.npy'\n",
    "np.save(pathres, ResultMCMC_Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining in-eclipse and in-transit index\n",
    "\n",
    "# generating transit model\n",
    "\n",
    "if 't0' in p0_labels:\n",
    "    t0MCMC = p0_mcmc[np.where(p0_labels == 't0')[0][0]]\n",
    "else:\n",
    "    t0MCMC = p0_obj['t0']\n",
    "if 'per' in p0_labels:\n",
    "    perMCMC = p0_mcmc[np.where(p0_labels == 'per')[0][0]]\n",
    "else:\n",
    "    perMCMC = p0_obj['per']\n",
    "if 'rp' in p0_labels:\n",
    "    rpMCMC = p0_mcmc[np.where(p0_labels == 'rp')[0][0]]\n",
    "else:\n",
    "    rpMCMC = p0_obj['rp']\n",
    "if 'a' in p0_labels:\n",
    "    aMCMC = p0_mcmc[np.where(p0_labels == 'a')[0][0]]\n",
    "else:\n",
    "    aMCMC = p0_obj['a']\n",
    "if 'inc' in p0_labels:\n",
    "    incMCMC = p0_mcmc[np.where(p0_labels == 'inc')[0][0]]\n",
    "else:\n",
    "    incMCMC = p0_obj['inc']\n",
    "if 'ecosw' in p0_labels:\n",
    "    ecoswMCMC = p0_mcmc[np.where(p0_labels == 'ecosw')[0][0]]\n",
    "else:\n",
    "    ecoswMCMC = p0_obj['ecosw']\n",
    "if 'esinw' in p0_labels:\n",
    "    esinwMCMC = p0_mcmc[np.where(p0_labels == 'esinw')[0][0]]\n",
    "else:\n",
    "    esinwMCMC = p0_obj['esinw']\n",
    "if 'q1' in p0_labels:\n",
    "    q1MCMC = p0_mcmc[np.where(p0_labels == 'q1')[0][0]]\n",
    "else:\n",
    "    q1MCMC = p0_obj['q1']\n",
    "if 'q2' in p0_labels:\n",
    "    q2MCMC = p0_mcmc[np.where(p0_labels == 'q2')[0][0]]\n",
    "else:\n",
    "    q2MCMC = p0_obj['q2']\n",
    "if 'fp'in p0_labels:\n",
    "    fpMCMC = p0_mcmc[np.where(p0_labels == 'fp')[0][0]]\n",
    "else:\n",
    "    fpMCMC = p0_obj['fp']\n",
    "\n",
    "eccMCMC = np.sqrt(ecoswMCMC**2 + esinwMCMC**2)\n",
    "wMCMC   = np.arctan2(esinwMCMC, ecoswMCMC)\n",
    "u1MCMC  = 2*np.sqrt(q1MCMC)*q2MCMC\n",
    "u2MCMC  = np.sqrt(q1MCMC)*(1-2*q2MCMC)\n",
    "\n",
    "trans, t_sec, true_anom = astro_models.transit_model(time, t0MCMC, perMCMC, rpMCMC,\n",
    "                                                     aMCMC, incMCMC, eccMCMC, wMCMC,\n",
    "                                                     u1MCMC, u2MCMC)\n",
    "# generating secondary eclipses model\n",
    "eclip = astro_models.eclipse(time, t0MCMC, perMCMC, rpMCMC, aMCMC, incMCMC, eccMCMC, wMCMC,\n",
    "                             fpMCMC, t_sec)\n",
    "\n",
    "# get in-transit indices\n",
    "ind_trans  = np.where(trans!=1)\n",
    "# get in-eclipse indices\n",
    "ind_eclip  = np.where((eclip!=(1+fpMCMC)))\n",
    "# seperating first and second eclipse\n",
    "ind_ecli1 = ind_eclip[0][np.where(ind_eclip[0]<int(len(time)/2))]\n",
    "ind_ecli2 = ind_eclip[0][np.where(ind_eclip[0]>int(len(time)/2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = flux/mcmc_detec - mcmc_lightcurve\n",
    "\n",
    "data1 = [xdata, ydata, psfxw, psfyw, flux, residual]\n",
    "data2 = [xdata[ind_ecli1], ydata[ind_ecli1], psfxw[ind_ecli1], psfyw[ind_ecli1], flux[ind_ecli1], residual[ind_ecli1]]\n",
    "data3 = [xdata[ind_trans], ydata[ind_trans], psfxw[ind_trans], psfyw[ind_trans], flux[ind_trans], residual[ind_trans]]\n",
    "data4 = [xdata[ind_ecli2], ydata[ind_ecli2], psfxw[ind_ecli2], psfyw[ind_ecli2], flux[ind_ecli2], residual[ind_ecli2]]\n",
    "\n",
    "plotname = savepath + 'MCMC_'+mode+'_7.pdf'\n",
    "make_plots.triangle_colors(data1, data2, data3, data4, plotname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SPCA]",
   "language": "python",
   "name": "conda-env-SPCA-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
